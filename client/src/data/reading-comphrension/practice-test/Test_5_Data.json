[
  {
    "test_number": 5,
    "question_number": 1,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Salt enhances the flavor of food because it activates the taste receptors of the desired flavors.",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "The statement is NOT correct, but the reason is correct",
        "images": [],
        "percentage_selected": "(1.4%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "The statement is correct, but the reason is NOT",
        "images": [],
        "percentage_selected": "(81.9%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "Both the statement and reason are correct and related",
        "images": [],
        "percentage_selected": "(14.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Both the statement and reason are correct but NOT related",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "NEITHER the statement NOR the reason is correct",
        "images": [],
        "percentage_selected": "(0.8%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "The statement is correct, but the reason is NOT",
    "analytics": {
      "percent_correct": "81.9%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "To answer questions like these, it may be helpful to identify the statement and the reason. The statement is the main point that it being made, while the reason is used as a support for the statement. The reason is often found AFTER words like “because”. Hence, in this question, the statement is that “salt enhances the flavor of food” and the reason is that salt enhances food favor because “it activates the taste receptors of the desired flavors.” Paragraph 4 states: “One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.” Since salt enhances the favor of food, the statement is correct. However, salt enhances the food through the reduction of an individual’s perception of bitterness, NOT through activating the taste receptors of desired flavors. While the author does acknowledge that salt enhances the perception of salty, sweet, and umami tastes, they do not claim that salt activates the receptors for these flavors. There are alternative mechanisms through which salt might enhance these flavors without directly stimulating these receptors. Hence, the reasoning is NOT correct. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. The statement is NOT correct, but the reason is correct – is incorrect because the statement is correct as evidenced by paragraph 4 when it states that “…salt enhances the flavor of food.” On the other hand, the reasoning is NOT correct because salt enhances food flavor “…via the reduction of our perception of bitterness,” (Paragraph 4) NOT through activating the taste receptors of the desired flavors. While the author does acknowledge that salt “…accentuates our perception of salty, sweet, and umami…” (paragraph 4), they do not claim that salt activates the receptors for these flavors. There are alternative mechanisms through which salt might enhance these flavors without directly stimulating these receptors. Option C. Both the statement and reason are correct and related – is incorrect because although the statement is correct as evidenced by paragraph 4 when it states that “…salt enhances the flavor of food,” the reasoning is NOT correct because salt enhances food flavor “…via the reduction of our perception of bitterness,” (Paragraph 4) NOT through activating the taste receptors of the desired flavors. While the author does acknowledge that salt “…accentuates our perception of salty, sweet, and umami…” (paragraph 4), they do not claim that salt activates the receptors for these flavors. There are alternative mechanisms through which salt might enhance these flavors without directly stimulating these receptors. Option D. Both the statement and reason are correct but NOT related – is incorrect because although the statement is correct as evidenced by paragraph 4 when it states that “…salt enhances the flavor of food,” the reasoning is NOT correct because salt enhances food flavor “…via the reduction of our perception of bitterness,” (Paragraph 4) NOT through activating the taste receptors of the desired flavors. While the author does acknowledge that salt “…accentuates our perception of salty, sweet, and umami…” (paragraph 4), they do not claim that salt activates the receptors for these flavors. There are alternative mechanisms through which salt might enhance these flavors without directly stimulating these receptors. Option E. NEITHER the statement NOR the reason is correct – is incorrect because the statement is correct as evidenced by paragraph 4 when it states that “…salt enhances the flavor of food.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 2,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "With which of the following statements would the author most likely agree?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "A diet made up of foods high in salt would not impact circulation efficiency over time",
        "images": [],
        "percentage_selected": "(2.1%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "No meaningful contribution was made to salt culture on the part of the Romans",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Adding salt to coffee can counteract the beverage’s bitterness",
        "images": [],
        "percentage_selected": "(88.6%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Breaking apart 1 mol of salt releases insignificant energy",
        "images": [],
        "percentage_selected": "(6.8%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Egyptian mummies were exempt from taxation",
        "images": [],
        "percentage_selected": "(1.5%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Adding salt to coffee can counteract the beverage’s bitterness",
    "analytics": {
      "percent_correct": "88.6%",
      "time_spent": "0 min, 5 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 4 states: “One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.” The author believes that adding salt to bitter food can reduce one’s perception of the bitter taste. Hence, the author would most likely agree that coffee’s bitterness can be counteracted by adding salt. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. A diet made up of foods high in salt would not impact circulation efficiency over time – is incorrect because paragraph 3 states that “Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.” Evidently, consuming high salt foods can affect an individual’s circulatory system. Option B. No meaningful contribution was made to salt culture on the part of the Romans – is incorrect because this is contradicted in the first paragraph when it states that “…the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables.” Evidently, Romans contributed significantly to the salt culture. Option D. Breaking apart 1 mol of salt releases insignificant energy – is incorrect because paragraph 7 states that “…if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas.” By equating the energy released when breaking apart 1 mol of salt to the energy given off when burning 1 mol of natural gas, the author demonstrates that breaking apart salt releases a significant amount of energy. Option E. Egyptian mummies were exempt from taxation – is incorrect because this is contradicted by paragraph 6 when it states that “Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label.” Since mummies were sometimes taxed due to their “salted meat” label, they were NOT exempt from taxation.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 3,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Which of the following physiological issues is most likely to result from sodium chloride deficiency?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Muscle spasms",
        "images": [],
        "percentage_selected": "(77.6%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Hypertension",
        "images": [],
        "percentage_selected": "(13.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Excess energy",
        "images": [],
        "percentage_selected": "(2.4%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Chronic stress",
        "images": [],
        "percentage_selected": "(1.6%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Acid reflux",
        "images": [],
        "percentage_selected": "(5.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Muscle spasms",
    "analytics": {
      "percent_correct": "77.6%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 3 states: “Sodium ions are critical to the transmission of nervous signals and muscular control .” An individual that has a sodium chloride deficit would lack sodium ions. Given passage information, this individual would experience problems with their nervous and/or muscular system. Muscle spasms are a result of a lack of muscular control or improper transmission of nerve signals. Hence, it is possible that an individual with a sodium chloride deficit would have muscle spasms. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Hypertension – is incorrect because paragraph 3 states that “Sodium ions are critical to the transmission of nervous signals and muscular control.” Hypertension is high blood pressure. Given passage information, we cannot confidently conclude that abnormal nervous signals and muscular control results in high blood pressure. Therefore, there is no support for this option. Option C. Excess energy – is incorrect because although paragraph 3 states that “Sodium ions are critical to the transmission of nervous signals and muscular control,” there is no evidence that indicates that a lack of sodium ions would result in an increase in energy. On the contrary, it is more plausible that an individual feels more tired, or they have less energy, since they lack sodium ions for proper nervous and muscular functioning. Option D. Chronic stress – is incorrect because paragraph 3 states that “Sodium ions are critical to the transmission of nervous signals and muscular control.” In order to accept this option as the answer, we need to establish that stress is the result of nervous signals and muscular control. However, given passage information, we cannot confidently conclude this connection. Thus, we cannot say that abnormal nervous signals and muscular control results in chronic stress. Option E. Acid reflux – is incorrect because paragraph 3 states that “Sodium ions are critical to the transmission of nervous signals and muscular control.” Acid reflux is a gastrointestinal issue. Given passage information, we cannot confidently conclude that abnormal nervous signals and muscular control results in acid reflux. Therefore, there is no support for this option.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 4,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Which of the following describes the reaction that results in the formation of barium sulfate?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Sodium chloride is used as a reactant",
        "images": [],
        "percentage_selected": "(2.7%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Chloride ions exchange places with sulfate ions",
        "images": [],
        "percentage_selected": "(79.3%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "A white precipitate is dissolved into the solution",
        "images": [],
        "percentage_selected": "(4.4%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Sodium sulfate is mixed with barium sulfate",
        "images": [],
        "percentage_selected": "(8.3%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Sodium chloride precipitates out of the solution",
        "images": [],
        "percentage_selected": "(5.3%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Chloride ions exchange places with sulfate ions",
    "analytics": {
      "percent_correct": "79.3%",
      "time_spent": "34 min, 36 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 9 states: “Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.” Therefore, Option B is the correct answer.",
      "poe_text": "Option A. Sodium chloride is used as a reactant – is incorrect because paragraph 9 describes the reaction that produces barium sulfate and states that “Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, […] When aqueous sodium sulfate and aqueous barium chloride are mixed, […] a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.” Thus, sodium chloride is a product, NOT a reactant, of the reaction that produces barium sulfate. Option C. A white precipitate is dissolved into the solution – is incorrect because paragraph 9 describes the reaction that produces barium sulfate and states that “As the compounds interact and exchange ions, a white precipitate emerges in the solution. […] a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.” Thus, a white precipitate is NOT dissolved into the solution during this reaction, rather, a white precipitate is produced in the form of barium sulfate. Option D. Sodium sulfate is mixed with barium sulfate – is incorrect because paragraph 9 describes the reaction that produces barium sulfate and states that “…aqueous sodium sulfate and aqueous barium chloride are mixed…” Thus, sodium sulfate is mixed with barium chloride, NOT barium sulfate, making this option incorrect. Option E. Sodium chloride precipitates out of the solution – is incorrect because paragraph 9 describes the reaction that produces barium sulfate and states that “About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.” Thus, barium sulfate forms the precipitate, NOT sodium chloride - which stays in aqueous or dissolved form.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 5,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Use the following information to answer questions 5-7. Table 1: Properties of Alkali Metals Which of the following alkali metals, when combined with chlorine, will have the lowest lattice energy?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Li",
        "images": [],
        "percentage_selected": "(16.9%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Na",
        "images": [],
        "percentage_selected": "(2.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "K",
        "images": [],
        "percentage_selected": "(0.7%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Rb",
        "images": [],
        "percentage_selected": "(0.7%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Cs",
        "images": [],
        "percentage_selected": "(79.5%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "Cs",
    "analytics": {
      "percent_correct": "79.5%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 7 states: “ Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. […] Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size , on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.” Since all alkali metals have the same charge as +1, their ionic size is the most important factor in comparing their lattice energies. The table presents the ionic radius of the alkali metals, which indicates ionic size. The passage tells us that ionic size is inversely proportional to lattice energy, thus, the greater the ionic size, the smaller the lattice energy. From the table, we see that cesium, represented by the symbol “Cs”, has the greatest ionic size and hence, the smallest lattice energy. Therefore, Option E is the correct answer.",
      "poe_text": "Option A. Li – is incorrect because lithium has the smallest ionic radius of the options listed. Paragraph 7 states that “Ionic size, on the other hand, has an inversely proportional relationship with lattice energy,” hence, the smaller the ionic size, the greater the lattice energy. From the options listed, lithium has the greatest, NOT lowest, lattice energy. Option B. Na – is incorrect because sodium has a smaller ionic radius than potassium, rubidium, and cesium. Paragraph 7 states that “Ionic size, on the other hand, has an inversely proportional relationship with lattice energy,” hence, the smaller the ionic size, the greater the lattice energy. Sodium would thus have a greater lattice energy than potassium, rubidium, and cesium. Option C. K – is incorrect because potassium has a smaller ionic radius than rubidium and cesium. Paragraph 7 states that “Ionic size, on the other hand, has an inversely proportional relationship with lattice energy,” hence, the smaller the ionic size, the greater the lattice energy. Potassium would thus have a greater lattice energy than rubidium and cesium. Option D. Rb – is incorrect because rubidium has a smaller ionic radius than cesium. Paragraph 7 states that “Ionic size, on the other hand, has an inversely proportional relationship with lattice energy,” hence, the smaller the ionic size, the greater the lattice energy. Rubidium would thus have a greater lattice energy than cesium.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 6,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Use the following information to answer questions 5-7. Table 1: Properties of Alkali Metals Which of the following relationships between the properties of alkali metals can be drawn?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "The lattice energy is directly proportional to ionic size",
        "images": [],
        "percentage_selected": "(7.5%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "The first ionization energy is directly proportional to ionic size",
        "images": [],
        "percentage_selected": "(5.6%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "The molecular weight is directly proportional to first ionization energy",
        "images": [],
        "percentage_selected": "(4.2%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "The molecular weight is inversely proportional to lattice energy",
        "images": [],
        "percentage_selected": "(76.3%)",
        "is_correct": true
      },
      {
        "label": "E.",
        "text": "The molecular weight is inversely proportional to ionic size",
        "images": [],
        "percentage_selected": "(6.3%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "The molecular weight is inversely proportional to lattice energy",
    "analytics": {
      "percent_correct": "76.3%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Although the passage does not directly discuss the relationship between the molecular weight and lattice energy, the table above can be used to answer this question. The table shows that as the molecular weight of the element increases, the ionic radius also increases. This suggests that the molecular weight is directly proportional to ionic size. Paragraph 7 states that: “ Ionic size , on the other hand, has an inversely proportional relationship with lattice energy : the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.” Since molecules with smaller molecular weights also have smaller ionic sizes, their lattice energies will be greater because they form more rigid ionic bonds. Thus, the molecular weight is inversely proportional to lattice energy. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. The lattice energy is directly proportional to ionic size – is incorrect because paragraph 7 states that “Ionic size, on the other hand, has an inversely proportional relationship with lattice energy.” Hence, the lattice energy is inversely proportional, NOT directly proportional to ionic size. Option B. The first ionization energy is directly proportional to ionic size – is incorrect because Table 1 shows as the ionic size increases, the first ionization energy decreases. This suggests an inversely proportional relationship, NOT a directly proportional one. Option C. The molecular weight is directly proportional to first ionization energy – is incorrect because Table 1 shows as the molecular weight increases, the first ionization energy decreases. This suggests an inversely proportional relationship, NOT a directly proportional one. Option E. The molecular weight is inversely proportional to ionic size – is incorrect because Table 1 shows as the molecular weight increases, the ionic size also increases. This suggests a directly proportional relationship, NOT an inversely proportional one.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 7,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Use the following information to answer questions 5-7. Table 1: Properties of Alkali Metals Suppose a scientist synthesized a new element in the laboratory with a molecular weight of 40.03 amu and an ionic charge of +2. Which of the following conclusions can be drawn regarding this element?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "It has a smaller ionic charge than any alkali metal",
        "images": [],
        "percentage_selected": "(5.7%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "When combined with fluorine, it has a greater lattice energy than cesium fluoride",
        "images": [],
        "percentage_selected": "(60.5%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "When combined with fluorine, it has a smaller lattice energy than lithium fluoride",
        "images": [],
        "percentage_selected": "(29.7%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "It has a smaller molecular weight than sodium",
        "images": [],
        "percentage_selected": "(3.1%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "It has a greater molecular weight than cesium",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "When combined with fluorine, it has a greater lattice energy than cesium fluoride",
    "analytics": {
      "percent_correct": "60.5%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 7 states that: “ Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy.” Lattice energy is directly proportional to the charge difference between the elements of a compound. This new compound has an ionic charge of +2, whereas sodium has an ionic charge of +1. When this new compound combines with fluorine, its charge difference is greater than sodium’s. Hence, this new compound will have a greater lattice energy than sodium fluoride. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. It has a smaller ionic charge than any alkali metal – is incorrect because the question indicates that this new element has an ionic charge of +2. The table states that all the alkali metals have an ionic charge of +1, which is less than the ionic charge of the new element. Therefore, this element has a greater, NOT smaller, ionic charge than any alkali metal. Option C. When combined with fluorine, it has a smaller lattice energy than lithium fluoride – is incorrect because paragraph 7 states that: “Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy.” Lattice energy is directly proportional to the charge difference between the elements of a compound. This new compound has an ionic charge of +2, whereas lithium has an ionic charge of +1. When this new compound combines with fluorine, its charge difference is greater than lithium’s. Hence, this new compound will have a greater, NOT smaller, lattice energy than lithium fluoride. Option D. It has a smaller molecular weight than sodium – is incorrect because the table states that sodium’s molecular weight is 22.99 amu. The new element has a molecular weight of 40.03 amu, which is greater, NOT smaller, than the molecular weight of sodium, making this option incorrect. Option E. It has a greater molecular weight than cesium – is incorrect because the table states that cesium’s molecular weight is 132.91 amu. The new element has a molecular weight of 40.03 amu, which is smaller, NOT greater, than the molecular weight of cesium, making this option incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 8,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Which of the following traits makes barium sulfate significant as a radiographic contrasting agent?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Density",
        "images": [],
        "percentage_selected": "(90.5%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Reactivity",
        "images": [],
        "percentage_selected": "(5.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Fast absorption",
        "images": [],
        "percentage_selected": "(3.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Affordability",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Accessibility",
        "images": [],
        "percentage_selected": "(0.9%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Density",
    "analytics": {
      "percent_correct": "90.5%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 10 states: “Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen.” The author attributes barium sulfate’s dense structure to its ability to block X-rays and act as a radiographic contrasting agent. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Reactivity – is incorrect because paragraph 10 states that “…In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.” From this passage excerpt, it can be inferred that barium sulfate, unlike other analogs, remains insoluble when ingested and does NOT react with the body. Furthermore, when discussing why barium sulfate acts as a good radiographic contrasting agent, the author states that it is “…Due to a highly dense structure […] the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen,” (paragraph 10). Hence, the author attributes barium sulfate’s dense structure, NOT reactivity, to its ability to act as a radiographic contrasting agent. Option C. Fast absorption – is incorrect because the author never mentions barium sulfate’s rate of absorption. Rather, in paragraph 10, the author describes barium sulfate’s ability to act as a radiographic contrasting agent by stating that “…Due to a highly dense structure […] the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen.” Option D. Affordability – is incorrect because the author never mentions barium sulfate’s affordability. Rather, in paragraph 10, the author describes barium sulfate’s ability to act as a radiographic contrasting agent by stating that “…Due to a highly dense structure […] the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen.” Option E. Accessibility – is incorrect because the author never mentions barium sulfate’s accessibility. Rather, in paragraph 10, the author describes barium sulfate’s ability to act as a radiographic contrasting agent by stating that “…Due to a highly dense structure […] the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 9,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Which of the following civilizations used salt as currency?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Greek",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Persians",
        "images": [],
        "percentage_selected": "(0.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Romans",
        "images": [],
        "percentage_selected": "(99%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Egyptians",
        "images": [],
        "percentage_selected": "(0.5%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Balkans",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Romans",
    "analytics": {
      "percent_correct": "99%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 1 states: “…the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’.” Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Greek – is incorrect because although the author states that salt “…held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians,” (Paragraph 1), the author never states that the Greeks used salt as a method of payment. Whereas, regarding the Romans, the author asserts that the Roman Empire used “…salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’,” (Paragraph 1). Option B. Persians – is incorrect because Persians are never mentioned in the passage. Option D. Egyptians – is incorrect because although the author states that salt “…held significant cultural meaning to eminent civilizations like […] the Egyptians…,” (Paragraph 1), the author never states that the Egyptians used salt as a method of payment. Whereas, regarding the Romans, the author asserts that the Roman Empire used “…salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’,” (Paragraph 1). Option E. Balkans – is incorrect because paragraph 2 mentions the Balkans when it states: “The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC.” Hence, the author refers to the Balkans during their discussion on how cities were named after salt. On the other hand, the author mentions salt being used a method of payment in paragraph 1 when they write that the Roman Empire used “…salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 10,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Each of the following are mentioned as practical uses involving salt, EXCEPT one. Which one is the EXCEPTION?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Mummification",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Pickle-preservation",
        "images": [],
        "percentage_selected": "(0.6%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Production of barium sulfate",
        "images": [],
        "percentage_selected": "(2.1%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Leather curing",
        "images": [],
        "percentage_selected": "(2.7%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Liquor chaser",
        "images": [],
        "percentage_selected": "(93.5%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "Liquor chaser",
    "analytics": {
      "percent_correct": "93.5%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 6 states: “The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. […] Mummies were referred to as “salted meat”…” Additionally, paragraph 5 states: “Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness.” Furthermore, paragraph 9 states: “Sodium chloride is also the product of an important chemical reaction that yields barium sulfate .” Lastly, paragraph 11 states: “[Salt] was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles.” Hence, the passage mentions mummification, pickle-preservation, barium sulfate production, and leather curing as practical uses of salt. However, liquor chaser is never mentioned in the passage, making it the exception. Therefore, Option E is the correct answer.",
      "poe_text": "Option A. Mummification – is incorrect because paragraph 6 states that “The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. […] Mummies were referred to as “salted meat”…” Since the passage mentions mummification as a practical use of salt, it cannot be an exception. Option B. Pickle-preservation – is incorrect because paragraph 5 states that “Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness.” Since the passage mentions pickle-preservation as a practical use of salt, it cannot be an exception. Option C. Can be used to produce barium sulfate – is incorrect because paragraph 9 states that “Sodium chloride is also the product of an important chemical reaction that yields barium sulfate.” Since the passage mentions barium sulfate production as a practical use involving salt, it cannot be an exception. Option D. Leather curing – is incorrect because paragraph 11 states: “[Salt] was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles.” Since the passage mentions leather curing as a practical use of salt, it cannot be an exception.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 11,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "The barium sulfate solution should not be shaken before ingesting, as doing so could cause it to pass through the soft tissues of the intestines.",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "The statement is NOT correct, but the reason is correct",
        "images": [],
        "percentage_selected": "(22.3%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "The statement is correct, but the reason is NOT",
        "images": [],
        "percentage_selected": "(7.7%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Both the statement and reason are correct and related",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Both the statement and reason are correct but NOT related",
        "images": [],
        "percentage_selected": "(2.4%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "NEITHER the statement NOR the reason is correct",
        "images": [],
        "percentage_selected": "(66.3%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "NEITHER the statement NOR the reason is correct",
    "analytics": {
      "percent_correct": "66.3%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "To answer questions like these, it may be helpful to identify the statement and the reason. The statement is the main point that it being made, while the reason is used as a support for the statement. The reason is often found AFTER words like “because”. Hence, in this question, the statement is that “The barium sulfate solution should not be shaken before ingesting” and the reason is that the solution should not be shaken “as doing so could cause it to pass through the soft tissues of the intestines.” Paragraph 9 states: “As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking.” Hence, the statement is incorrect because the barium sulfate solution should be shaken before drinking. The reasoning is also incorrect because the solution needs to be shaken because the barium sulfate settles at the bottom. The shaking of the solution has nothing to do with the solution passing through the intestine. In fact, the author never claims that the solution can pass through the intestine, only that X-rays normally passes through the soft tissues of the intestine. Therefore, Option E is the correct answer.",
      "poe_text": "Option A. The statement is NOT correct, but the reason is correct – is incorrect because although the statement is incorrect, the reason is also incorrect because the shaking of the solution has nothing to do with the solution passing through the intestine. In fact, the author never claims that the solution can pass through the intestine, only that “…X-rays that would normally pass through the soft tissue of the stomach and intestines,” (Paragraph 9). Option B. The statement is correct, but the reason is NOT – is incorrect because although the reason is incorrect, the statement is also incorrect. This is evidenced by paragraph 9 when it states that “…barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking.” Option C. Both the statement and reason are correct and related – is incorrect because the statement is incorrect because paragraph 9 states that “…barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking.” The reasoning is also incorrect because the shaking of the solution has nothing to do with the solution passing through the intestine. In fact, the author never claims that the solution can pass through the intestine, only that “…X-rays that would normally pass through the soft tissue of the stomach and intestines,” (Paragraph 9). Option D. Both the statement and reason are correct but NOT related – is incorrect because the statement is incorrect because paragraph 9 states that “…barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking.” The reasoning is also incorrect because the shaking of the solution has nothing to do with the solution passing through the intestine. In fact, the author never claims that the solution can pass through the intestine, only that “…X-rays that would normally pass through the soft tissue of the stomach and intestines,” (Paragraph 9).",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 12,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "How much salt is utilised for human consumption yearly?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "6 thousand tonnes",
        "images": [],
        "percentage_selected": "(0.8%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "12 thousand tonnes",
        "images": [],
        "percentage_selected": "(5%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "6 million tonnes",
        "images": [],
        "percentage_selected": "(4.7%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "12 million tonnes",
        "images": [],
        "percentage_selected": "(88.5%)",
        "is_correct": true
      },
      {
        "label": "E.",
        "text": "15 million tonnes",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "12 million tonnes",
    "analytics": {
      "percent_correct": "88.5%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 5 states: “In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.” 6 percent of 200 million tonnes can be obtained by multiplying 6/100 by 200 million. This gives us 12 million tonnes as the answer. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. 6 thousand tonnes – is incorrect because paragraph 5 states that “…only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.” 6 percent of 200 million is 12 million tonnes, NOT 6 thousand tonnes, making this option incorrect. Option B. 12 thousand tonnes – is incorrect because paragraph 5 states that “…only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.” 6 percent of 200 million is 12 million tonnes, NOT 12 thousand tonnes, making this option incorrect. Option C. 6 million tonnes – is incorrect because paragraph 5 states that “…only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.” 6 percent of 200 million is 12 million tonnes, NOT 6 million tonnes, making this option incorrect. Option E. 15 million tonnes – is incorrect because paragraph 5 states that “…only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.” 6 percent of 200 million is 12 million tonnes, NOT 15 million tonnes, making this option incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 13,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Salt preserves meat by depriving which of the following of vital nutrients?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Fungi",
        "images": [],
        "percentage_selected": "(0.1%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Moisture",
        "images": [],
        "percentage_selected": "(42.4%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Fruit flies",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Mold",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Bacteria",
        "images": [],
        "percentage_selected": "(56.9%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "Bacteria",
    "analytics": {
      "percent_correct": "56.9%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 5 states: “Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria.” Salt desiccates (removes water) from the environment. For moisture-feeding bacteria, water is a necessity. Hence, salt deprives these bacteria from their essential nutrients and consequently, preserves the meat. Therefore, Option E is the correct answer.",
      "poe_text": "Option A. Fungi – is incorrect because paragraph 5 states that “Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria,” NOT fungi. Option B. Moisture – is incorrect because paragraph 5 states that “Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria.” Since salt desiccates (removes moisture) from the environment, it kills the moisture-feeding bacteria and preserves the meat. Moisture is hence the nutrient, and the bacteria is the organism being deprived. Option C. Fruit flies – is incorrect because paragraph 5 states that “Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria,” NOT fruit flies. Option D. Mold – is incorrect because paragraph 5 states that “Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria,” NOT mold.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 14,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Which of the following outlines the reasons that certain civilizations salted and smoked insects?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "It was a traditional rite which had religious importance",
        "images": [],
        "percentage_selected": "(0.8%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "It facilitated their ability to conserve scarce foods",
        "images": [],
        "percentage_selected": "(92.3%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "It reduced the acrid taste of some insects",
        "images": [],
        "percentage_selected": "(4.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "It was an effective way to make use of any extra salt stores",
        "images": [],
        "percentage_selected": "(1.2%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "The people of the culture wanted to keep their blood pH levels consistent",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "It facilitated their ability to conserve scarce foods",
    "analytics": {
      "percent_correct": "92.3%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 5 states: “In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.” Since crickets were the sole food source for people in ancient Ethipia and Libya and since these insects were found only during the spring, the people of these cultures preserved this scarce insect through salting and smoking. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. It was a traditional rite which had religious importance – is incorrect because paragraph 5 states that “In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long.” Although salting and smoking these insects was traditional, nothing in the passage indicates that this practice held any religious significance. Rather, it states that these people engaged in these practices to preserve the food and “…sustain themselves year-long.” Option C. It reduced the acrid taste of some insects – is incorrect because although paragraph 4 discusses how salt decreases the bitterness in food, this does not describe the motivation behind why certain cultures salted and smoked insects. Paragraph 5, on the other hand, states that “In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long.” Thus, these people engaged in these practices to preserve the food and “…sustain themselves year-long.” Option D. It was an effective way to make use of any extra salt stores – is incorrect because paragraph 5 states that “In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long.” Nothing in the passage indicates that salt was in surplus supply. Rather, the passage states that people smoked and salted insects to preserve the food and “…sustain themselves year-long.” Option E. The people of the culture wanted to keep their blood pH levels consistent – is incorrect because although paragraph 3 discusses the effects of salt on pH, this does not describe the motivation behind why cultures salted and smoked insects. Paragraph 5, on the other hand, states that “In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long.” Thus, these people engaged in these practices to preserve the food and “…sustain themselves year-long.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 15,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "Where did the initial dispute regarding salt occur?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Bulgaria",
        "images": [],
        "percentage_selected": "(2.7%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Japan",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "America",
        "images": [],
        "percentage_selected": "(2.5%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "China",
        "images": [],
        "percentage_selected": "(93.7%)",
        "is_correct": true
      },
      {
        "label": "E.",
        "text": "Spain",
        "images": [],
        "percentage_selected": "(0.9%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "China",
    "analytics": {
      "percent_correct": "93.7%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 1 states: “Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals [salt] would surface.” Since this is the earliest mention of a dispute in the passage, it can be inferred that the first conflict over salt took place in China. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. Bulgaria – is incorrect because paragraph 2 mentions Bulgaria when it states that “The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works.” Hence, this country is mentioned in relation to the idea that salt influenced the naming of cities, NOT in relation to conflicts over this product. On the other hand, paragraph 1 states that the “…Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals [salt] would surface.” Since this is the earliest mention of conflict in the passage, it can be inferred that the first dispute over salt took place in China, NOT Bulgaria. Option B. Japan – is incorrect because this country is never mentioned in the passage. Option C. America – is incorrect because paragraph 1 states that “In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles.” Although a conflict took place in America, there is no indication in the passage that the dispute was over salt. Rather, the passage states that salt played a crucial role in assisting the war efforts. Additionally, the American Civil War was recent, as compared to the conflicts that took place in China in 6000 B.C which occurred “…during the dry season of the Yuncheng Salt Lake when dry flats of white crystals [salt] would surface.” (Paragraph 1). Option E. Spain – is incorrect because paragraph 2 mentions Spain when it states that “A few notches South exists Salt, a municipality of Catalonia in Spain.” Hence, this country is mentioned in relation to the idea that salt influenced the naming of cities, NOT in relation to any disputes over this product. On the other hand, paragraph 1 states that the “…Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals [salt] would surface.” Since this is the earliest mention of a dispute in the passage, it can be inferred that the first conflict over salt took place in China, NOT Spain.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 16,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "The passage mentions each of the following things that can be preserved by salt, EXCEPT one. Which one is the EXCEPTION?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Anchovies",
        "images": [],
        "percentage_selected": "(4%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Humans",
        "images": [],
        "percentage_selected": "(5.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Bacon",
        "images": [],
        "percentage_selected": "(87.5%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Ham",
        "images": [],
        "percentage_selected": "(0.4%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Crickets",
        "images": [],
        "percentage_selected": "(2.8%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Bacon",
    "analytics": {
      "percent_correct": "87.5%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 5 states: “Many foods such as anchovies , ham , and beans are salted for a longer shelf-life. […] In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets …” Additionally, paragraph 6 states: “The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. […] The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat”…” Thus, anchovies, ham, crickets, and humans can all be preserved by salt. Since bacon is never mentioned in the passage, it is the exception. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Anchovies – is incorrect because paragraph 5 states: “Many foods such as anchovies, ham, and beans are salted for a longer shelf-life.” Since, anchovies are mentioned, they cannot be an exception, making this option incorrect. Option B. Humans – is incorrect because paragraph 6 states: “The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. […] The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat”…” Since, humans are mentioned, they cannot be an exception, making this option incorrect. Option D. Ham – is incorrect because paragraph 5 states: “Many foods such as anchovies, ham, and beans are salted for a longer shelf-life.” Since, ham is mentioned, they cannot be an exception, making this option incorrect. Option E. Crickets – is incorrect because paragraph 5 states: “In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets…” Since, crickets are mentioned, they cannot be an exception, making this option incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 17,
    "passage": {
      "title": "Passage 1",
      "text": "(1). Long before it made its way onto dinner tables as a ubiquitous seasoning, salt was a sought-after commodity. Wars were fought over salt and it held significant cultural meaning to eminent civilizations like the Greeks, the Romans, the Byzantines, the Egyptians, and the Indians. Turning the dial of time back to 6000 B.C. shows that Chinese ancestors fought vicious wars during the dry season of the Yuncheng Salt Lake when dry flats of white crystals would surface. Later, the Roman Empire put a dent in the history of salt through their peculiar use of salt as a method of payment. Soldiers were not compensated by gold, but by packets of salt which birthed the word ‘salary’. Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables. In recent history, salt was central in the infamous American Civil War. It was not only used to preserve food, but also to cure leather for clothing, helmets, holsters, and horse saddles. (2). The gravitational attraction of salt is apparent in the slew of cities that have been named after it. The first city in Europe is called Solnitsata, in Bulgaria, which means salt works. The area was a salt mine which provided ample salt to the mountaineers of the Balkans since 5400 BC. A few notches South exists Salt, a municipality of Catalonia in Spain. Jordan took this homage one step further when they named their capital city Salt. In the United States, Salt Lake City is the largest city of Utah named after the Salt Lake. The evolution of salt from a prized possession to a universal compound is truly remarkable.\n\n(3). In early human history, the essential dietary salt, or sodium chloride to be technical, was derived from the hunting of animals and the harvest of vegetation. The role of salt as an electrolyte and osmotic solute in the body is indelible. Sodium ions are critical to the transmission of nervous signals and muscular control. Furthermore, as a key molecule involved in the osmotic regulation within the cellular microenvironments, salt determines the balance of fluids in body organs. On the other hand, chloride is a critical osmoregulatory component in blood pressure, blood volume, and pH. Considering the integral role of salt in homeostasis, its over-indulgence is inevitably harmful; high sodium intake is associated with a greater risk of stroke, cardiovascular problems, and kidney disease.\n\n(4). As the agricultural lifestyle progressed over thousands of years, humans became aware of the various practical applications of salt. One of the most profound discoveries in this forum was the realization that salt enhances the flavor of food via the reduction of our perception of bitterness. By reducing the bitterness taste receptor activity, it accentuates our perception of salty, sweet, and umami while minimizing that which is deemed undesirable.\n\n(5). Another major development in the timeline of salt was the realization that it could be used to preserve a host of foods. Salt prolongs the shelf-life of meat by desiccating moisture-feeding bacteria. Without water, the growth of the bacteria is significantly slowed, and their normal reproductive cycle is disrupted. Many foods such as anchovies, ham, and beans are salted for a longer shelf-life. Other foods like pickles and feta cheese are immersed in a salty solution called brine to preserve freshness. In ancient Ethiopia and Libya, a group of people called the Acridophagi, salted and smoked crickets. As their sole food source, which arrived at their settlements in the spring in great swarms, the salt enabled the settlers to sustain themselves year-long. In today’s age, only 6 percent of the 200 million tonnes of produced salt is attributed to human consumption.\n\n(6). The preservation of meat took a curious turn in Ancient Egypt, as salt held promises of eternity to the opulent. The body of the deceased had to be preserved by mummification so that the soul could reunite with the spirit of God and take pleasure in the afterlife. The primary process of mummification was preserving the body by dehydrating it using Natron, a natural salt found in Wadi Natrun. The body was drained of any liquids and left with the skin, hair, and muscles preserved. Mummies were referred to as “salted meat” and while they were transported down the Nile, they were often subjected to taxation due to this label. Once chemistry caught up with culture, however, the cryptic qualities of salt were demystified.\n\n(7). Sodium chloride comes in the form of rock salt (Himalayan) or sea salt (table). Although table salt is more common, the basic chemical structure remains intact. Sodium chloride is composed of two elements: sodium and chlorine. The basic properties of the sodium ion and the acidic nature of the chloride ion combine to form a neutral ionic compound. The molecular structure of sodium chloride is crystalline, which harnesses considerable lattice energy. Lattice energy is the amount of energy required to turn 1 mole of a substance from solid to gaseous form. Thus, if 1 mol of salt were to be separated into separate entities of gaseous sodium ions and chloride ions, it would require 787 kJ of energy. To put that into context, this amount of energy is nearly equivalent to the amount of heat given off by burning 1 mol of natural gas. Lattice energy is affected by charge and ionic size. The higher the charge difference between two compounds the stronger their attraction force. This means that the ionic bond between these compounds is more stable, hence, a higher lattice energy. Ionic size, on the other hand, has an inversely proportional relationship with lattice energy: the lower the ionic size of the molecules involved in the lattice, the closer they are in space, which means that they form more rigid ionic bonds that increase lattice energy.\n\n(8). Sodium is the 11th element on the periodic table and a member of the alkali metals, while chloride is the 17th element and a part of the halogen family. In general, alkali elements tend to lose their outstanding electron easily because it allows them to achieve a more stable state as an octet. Conversely, halogens only need one extra electron to complete their octet, so they tend to draw electrons away from their counterparts. The complementary nature of metals and halogens gives way to ionic compounds which are created through the transfer of electrons. Molecular compounds, on the other hand, are formed through the sharing of electrons, which can take place between metals and metalloids, two metalloids, a metalloid and a nonmetal, or two nonmetals.\n\n(9). Sodium chloride is also the product of an important chemical reaction that yields barium sulfate, a useful compound in radiology. When aqueous sodium sulfate and aqueous barium chloride are mixed, a double displacement reaction takes place. As the compounds interact and exchange ions, a white precipitate emerges in the solution. This signals that the sulfate ion has exchanged places with the chloride ion. About 10 minutes after the initial reaction, a white substance settles at the bottom of the colorless solution, which is a precipitated form of barium sulfate amidst aqueous sodium chloride.\n\n(10). Due to a highly dense structure, barium sulfate is ingested to imbue the gastrointestinal tract with contrast radiopacity. As a result, the X-rays that would normally pass through the soft tissue of the stomach and intestines, are blocked, enabling its visualization on the screen. Patients who are undergoing radiology are given the compound 90 minutes before their procedure. Since barium sulfate is an insoluble compound, it settles at the bottom of the heterogenous solution and must be shaken before drinking. Although it is an orally digested compound, intravenous fluid may also be administered to boost its effects. In most cases, barium sulfate passes through the digestive system without harm. Some barium sulfate analogs such as barium carbonate or barium fluoride elicit gastrointestinal issues in the form of diarrhea, vomiting, and stomach pain due to their solubility inside the stomach. Barium sulfate does not cause these effects as it remains insoluble.\n\n(11). From its impact on food to medicine, salt plays a vital role in facilitating day-to-day life. Reflecting on the lives lost in monopolizing salt while considering the cities that are named after it, it is surprising to realize that at some point, humans lost the appreciation for something that was once so cherished. Perhaps gratitude for this mundane member of the dinner table will bring forth more respect for how we consume our food."
    },
    "question": {
      "text": "The dual factors that influence lattice energy are ionic size and charge. Salad as a dish was first developed in ancient Rome.",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Both statements are TRUE",
        "images": [],
        "percentage_selected": "(61.3%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Both statements are FALSE",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "The first statement is TRUE, the second statement is FALSE",
        "images": [],
        "percentage_selected": "(36.5%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "The first statement is FALSE, the second statement is TRUE",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "The first statement is TRUE, the second statement is FALSE",
    "analytics": {
      "percent_correct": "36.5%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #1"
    },
    "category": "Passage #1",
    "explanation": {
      "concept_text": "Paragraph 7 states: “Lattice energy is affected by charge and ionic size.” Hence, the first statement is TRUE. On the other hand, paragraph 1 states: “Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables.” Salads already existed; the Romans merely coined the term “salad.” Hence, the second statement is FALSE. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Both statements are TRUE – is incorrect because although the first statement is indeed true, the second statement is false as indicated by paragraph 1 when it states that “Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables.” Thus, salads already existed; the Romans merely coined the term “salad.” Option B. Both statements are FALSE – is incorrect because although the second statement is indeed false, the first statement is true as indicated by paragraph 7 when it states that “Lattice energy is affected by charge and ionic size.” Option D. The first statement is FALSE, the second statement is TRUE – is incorrect because the first statement is true, NOT false, as indicated by paragraph 7 when it states that “Lattice energy is affected by charge and ionic size.” Additionally, the second statement is false, NOT true, as indicated by paragraph 1 when it states that “Romans also created the word salad, literally translating to \"salted\", deriving from the practice of salting leafy vegetables.” Thus, salads already existed; the Romans merely coined the term “salad.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 18,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Each of the following are used to determine the relative abundance of nucleic acid sequences in a target EXCEPT one. Which one is the EXCEPTION?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Silver-labeled targets",
        "images": [],
        "percentage_selected": "(2.4%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Chemiluminescence-labeled targets",
        "images": [],
        "percentage_selected": "(2.9%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Fluorophore-labeled targets",
        "images": [],
        "percentage_selected": "(1.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Hydrogen-labeled targets",
        "images": [],
        "percentage_selected": "(92.8%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "Hydrogen-labeled targets",
    "analytics": {
      "percent_correct": "92.8%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the phrase “nucleic acid sequences.” It can be presumed that a paragraph discussing this topic in-depth will include information relevant to the stem. If we note that paragraphs 1 and 2 discuss nucleic acid sequences, we should scan each to determine which tells us what is used to determine the relative abundance of nucleic acid sequences. Paragraph 1 reads: “Probe-target hybridization is usually detected and quantified by detection of fluorophore- , silver- , or chemiluminescence-labeled targets , to determine the relative abundance of nucleic acid sequences in the target.” This tells us that silver, fluorophore, and chemiluminescence are used but does NOT mention hydrogen-labeled targets . Therefore, Option D is the correct answer.",
      "poe_text": "Option A. Silver-labeled targets – is incorrect because in paragraph 1, the author mentions silver-labeled targets can determine the relative abundance of nucleic acid sequences in a target. Since it is mentioned, this is incorrect. Option B. Chemiluminescence-labeled targets – is incorrect because in paragraph 1, the author mentions chemiluminescence-labeled targets can determine the relative abundance of nucleic acid sequences in a target. Since it is mentioned, this is incorrect. Option C. Fluorophore labeled-targets – is incorrect because in paragraph 1, the author mentions fluorophore-labeled targets can determine the relative abundance of nucleic acid sequences in a target. Since it is mentioned, this is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 19,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "What is the advantage of a single-channel system?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Samples can influence raw data from other samples",
        "images": [],
        "percentage_selected": "(3.3%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "It is more cost-effective",
        "images": [],
        "percentage_selected": "(1.8%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "It simplifies the data comparison process",
        "images": [],
        "percentage_selected": "(57.2%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "It is more efficient to process",
        "images": [],
        "percentage_selected": "(1.7%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Arrays provide intensity data for multiple probes",
        "images": [],
        "percentage_selected": "(36%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "It simplifies the data comparison process",
    "analytics": {
      "percent_correct": "57.2%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should first locate the paragraph or paragraphs discussing single-channel systems; these are discussed in paragraphs 8 and 9: “In single-channel microarrays or one-colour microarrays, the arrays provide intensity data for each probe or probe set indicating a relative level of hybridization within the labeled target. A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-colour system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.” The only benefit of single-channel systems listed in both the above paragraph and the answer choices is it is easier to compare data using single-channel systems. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Samples can influence raw data from other samples – is incorrect because this would be a disadvantage, as implied by the wording in paragraph 8: “A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples.” Option B. It is more cost-effective – is incorrect because when describing single-channel microarrays in paragraphs 8 and 9, the author doesn’t mention affordability. Option D. It is more efficient to process – is incorrect because when describing single-channel microarrays in paragraphs 8 and 9, the author doesn’t mention processing time. Option E. Arrays provide intensity data for multiple probes – is incorrect because this is a description of the data the array provides, not the benefit.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 20,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Which of the following techniques is commonly employed amongst scientists to produce “in-house” print microarrays?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Printing with pointed pins",
        "images": [],
        "percentage_selected": "(81.7%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Electrochemistry",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Ink-jet printing",
        "images": [],
        "percentage_selected": "(6.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Printing with sticky pins",
        "images": [],
        "percentage_selected": "(7.4%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "The use of micromirror devices",
        "images": [],
        "percentage_selected": "(3.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Printing with pointed pins",
    "analytics": {
      "percent_correct": "81.7%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should first locate the paragraph or paragraphs discussing how microarrays are fabricated; this is discussed in paragraphs 4 and 5. “A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes, before depositing each probe at designated locations on the array surface…this technique is used by research scientists around the world to produce \"in-house\" printed microarrays from their own labs.” This tells us that scientists commonly produce “in-house” printed microarrays by printing with pointed pins. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Electrochemistry – is incorrect because in paragraph 4, the author says in paragraph 4 that, “Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on microelectrode arrays.” This is not the same as electrochemistry in general; thus, it is incorrect. Additionally, this is not cited as being a way to print “in-house” microarrays in a lab, only a way to make microarrays in general. Option C. Ink-jet printing – is incorrect because this is not cited in paragraphs 4 and 5 as being a way to print “in-house” microarrays in a lab, only a way to make microarrays in general. Option D. Printing with sticky pins – is incorrect because in paragraph 4, the author says, “Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides,” not sticky pins. Option E. The use of micromirror devices – is incorrect because this is not cited in paragraphs 4 and 5 as being a way to print “in-house” microarrays in a lab, only a way to make microarrays in general.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 21,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "What is the fluorescence emission wavelength of Cy3 green?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "570 nm",
        "images": [],
        "percentage_selected": "(98.4%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "580 nm",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "670 nm",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "750 nm",
        "images": [],
        "percentage_selected": "(0.1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "570 nm",
    "analytics": {
      "percent_correct": "98.4%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should locate the paragraph or paragraphs in the passage that mention fluorescence emission wavelengths. fluorescence emission wavelengths are discussed in paragraph 7: “Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm , and Cy5 red, that has a fluorescence emission wavelength of 670 nm.” This tells us that Cy3 green has a fluorescence emission wavelength of 570 nm. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. 580 nm – is incorrect because paragraph 7 states that Cy3 has a fluorescence emission wavelength of 570 nm, not 580 nm: “Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, that has a fluorescence emission wavelength of 670 nm.” Option C. 670 nm – is incorrect because paragraph 7 states that 670 nm is the fluorescence emission wavelength of Cy5 red, not Cy3 green: “Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, that has a fluorescence emission wavelength of 670 nm.” Option D. 750 nm – is incorrect because paragraph 7 states that Cy3 has a fluorescence emission wavelength of 570 nm, not 750 nm: “Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, that has a fluorescence emission wavelength of 670 nm.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 22,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "When juxtaposing the two-channel microarray system with the single-channel microarray system, what are single-channel microarrays known to employ?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Identical samples",
        "images": [],
        "percentage_selected": "(18.2%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "More than two fluorescent dyes",
        "images": [],
        "percentage_selected": "(5.8%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "cDNA",
        "images": [],
        "percentage_selected": "(2.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Other samples to compare",
        "images": [],
        "percentage_selected": "(67.6%)",
        "is_correct": true
      },
      {
        "label": "E.",
        "text": "The same technique",
        "images": [],
        "percentage_selected": "(5.6%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Other samples to compare",
    "analytics": {
      "percent_correct": "67.6%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should first locate the paragraph that offers a comparison between two-channel and single-channel microarrays. The two are compared in paragraph 8: “In single-channel microarrays or one-colour microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment.” This tells us that single-channel microarrays employ other samples for comparison. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. Identical samples – is incorrect because nowhere in the passage does the author mention that single-channel microarrays use identical samples. Instead, it is implied in paragraph 8 that they use other samples to compare. Option B. More than two fluorescent dyes – is incorrect because single-channel is also called one-color microarrays; if two-color microarrays use a combination of two fluorescent dyes, then one-color must use only one. Option C. cDNA – is incorrect because, in paragraph 7, the author says: “Two-colour microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared.” As two-color microarrays use cDNA, and the passage doesn’t say that one-color microarrays do too, this is incorrect. Option E. The same technique – is incorrect because two-color microarrays use hybridized cDNA with two samples to compare with two different fluorophores. One-color microarrays indicate a relative level of hybridization and need to be compared to other samples; these are two different techniques; thus, this option is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 23,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "What does the author imply that one must do to increase the strength of a feature signal in a microarray?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Increase the amount of fluorescent dye used",
        "images": [],
        "percentage_selected": "(6.7%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Increase the size of the microarray",
        "images": [],
        "percentage_selected": "(5.8%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Increase the time for Probe-target hybridization",
        "images": [],
        "percentage_selected": "(14.7%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Increase the amount of nonspecific bonding sequences",
        "images": [],
        "percentage_selected": "(4.9%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Increase the amount of target sample",
        "images": [],
        "percentage_selected": "(68%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "Increase the amount of target sample",
    "analytics": {
      "percent_correct": "68%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph or paragraphs discussing “feature signals.” Feature signals are only mentioned in paragraph 2: “Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization…[The] total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot…” This tells us that to increase the strength of a feature signal in a microarray, one must increase the amount of target sample. Therefore, Option E is the correct answer.",
      "poe_text": "Option A. Increase the amount of fluorescent dye used – is incorrect because, in paragraph 2, the author says that the strength of the signal from a feature depends on the amount of sample (fluorescently labeled sequence) binding to the probes. Increasing the amount of dye used would not increase the binding of the probes; thus, this is incorrect. Option B. Increase the size of the microarray – is incorrect because increasing microarray size is not discussed in the passage. Option C. Increase the time for Probe-target hybridization – is incorrect because, in paragraph 1, the author states: “Probe-target hybridization is usually detected and quantified by detection of fluorophore-, silver-, or chemiluminescence-labeled targets, to determine the relative abundance of nucleic acid sequences in the target.” This does not mention anything about increasing signal strength from a feature; thus, this is incorrect. Option D. Increase the amount of nonspecific bonding sequences – is incorrect because, in paragraph 2, the author states: “After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized.” This implies that nonspecific bonding sequences do not remain hybridized and, thus, don’t generate a signal. Increasing this would not increase the signal strength; thus, this is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 24,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "How many features can be placed on a single DNA microarray?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "One",
        "images": [],
        "percentage_selected": "(10.5%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Only a few",
        "images": [],
        "percentage_selected": "(2.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Hundreds",
        "images": [],
        "percentage_selected": "(2.1%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Thousands",
        "images": [],
        "percentage_selected": "(82.1%)",
        "is_correct": true
      },
      {
        "label": "E.",
        "text": "Millions",
        "images": [],
        "percentage_selected": "(2.9%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Thousands",
    "analytics": {
      "percent_correct": "82.1%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the phrase “DNA microarray.” If we note that this phrase is used in paragraphs 1 and 3, we should scan each of these paragraphs to ascertain whether either one includes details about the placement of features on DNA microarrays. This information can be found in paragraph 3: “The traditional solid-phase array is a collection of orderly microscopic \"spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface, made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray…” This tells us that thousands of features can be placed on a single DNA microarray. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. One – is incorrect because in paragraph 3, the author says that thousands of features can be placed on a single DNA microarray, not one. Option B. Only a few – is incorrect because in paragraph 3, the author says that thousands of features can be placed on a single DNA microarray, not a few. Option C. Hundreds – is incorrect because in paragraph 3, the author says that thousands of features can be placed on a single DNA microarray, not hundreds. Option E. Millions – is incorrect because in paragraph 3, the author says that thousands of features can be placed on a single DNA microarray, not millions.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 25,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Which of the following would describe shorter probes in oligonucleotide microarrays?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "High in density, expensively produced by Affymetrix",
        "images": [],
        "percentage_selected": "(2.4%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "High in density, cheaply produced by Affymetrix",
        "images": [],
        "percentage_selected": "(93.4%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "Low in density, expensively produced by Agilent",
        "images": [],
        "percentage_selected": "(1.1%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Low in density, cheaply produced by Affymetrix",
        "images": [],
        "percentage_selected": "(2.9%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Medium density, expensively produced by Agilent",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "High in density, cheaply produced by Affymetrix",
    "analytics": {
      "percent_correct": "93.4%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should scan the passage to locate the paragraph or paragraphs specifically discussing “oligonucleotide microarrays.” This type of microarray is discussed in paragraph 6, with the shorter probes in oligonucleotide microarrays described in the third sentence of this paragraph: “Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture.” This tells us that the shorter probes are high in density and cheaply produced by Affymetrix. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. High in density, expensively produced by Affymetrix – is incorrect because while this is mostly correct, the passage says that shorter probes are cheaply produced, not expensively. Option C. Low in density, expensively produced by Agilent – is incorrect because the passage says that shorter probes are high in density and cheap to manufacture. Additionally, the author provides the example of shorter probes produced by Affymetrix, not Agilent. Option D. Low in density, cheaply produced by Affymetrix – is incorrect because while this is mostly correct, the passage says that shorter probes are high in density. Option E. Medium density, expensively produced by Agilent – is incorrect because, while this is mostly correct, the passage says that shorter probes are high in density. They are also said to be cheaply manufactured by Affymetrix, not Agilent.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 26,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "What is the main idea of the passage?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "DNA microarrays represent the future of genomic testing",
        "images": [],
        "percentage_selected": "(5.6%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "The numerous types of DNA microarray streamline the intricate testing process",
        "images": [],
        "percentage_selected": "(22.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "The human genome’s extensiveness needs a precise measuring tool like microarrays",
        "images": [],
        "percentage_selected": "(2.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "DNA microarrays have varied purposes, but their role in genetic experimentation is crucial",
        "images": [],
        "percentage_selected": "(27.6%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "DNA microarrays measure gene expression and each form has a unique function",
        "images": [],
        "percentage_selected": "(41.8%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "DNA microarrays measure gene expression and each form has a unique function",
    "analytics": {
      "percent_correct": "41.8%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we need to summarize the passage into one sentence that captures the essence of the text. Typically, the first paragraph will provide crucial information as to the theme of the text, with the succeeding paragraphs expanding on this theme. In paragraph 1, the author mentions the statement below. This tells us that DNA microarrays are used to measure gene expression. “Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome.” The remainder of the paragraphs in the passage then discuss the various functions and forms of DNA microarrays as tools for measuring gene expression. Thus, we can say that the final answer choice encompasses the main idea of the passage because it mentions DNA microarrays, their use, and the fact that the text discusses the multiple forms and functions of DNA microarrays. Therefore, Option E is the correct answer.",
      "poe_text": "Option A. DNA microarrays represent the future of genomic testing – is incorrect because the author writes in the present tense and refrains from futuristic references. Option B. The numerous types of DNA microarray streamline the intricate testing process – is incorrect because this refers to only experimentation rather than the theme of genomic experimentation, which is the main idea of the passage. Option C. The human genome’s extensiveness needs a precise measuring tool like microarrays – is incorrect because this only addresses the article at a surface level and does not encompass the various forms of microarrays discussed in the passage. Option D. DNA microarrays have varied purposes, but their role in genetic experimentation is crucial – is incorrect because this suggests the author praises the technology repeatedly in the passage, which is not the case.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 27,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "What is the process of measuring gene expression through cDNA referred to as?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Profiling analysis",
        "images": [],
        "percentage_selected": "(3.6%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Dynamic micro-mirroring",
        "images": [],
        "percentage_selected": "(2.7%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Expression analysis",
        "images": [],
        "percentage_selected": "(88.6%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Photolithographic synthesis",
        "images": [],
        "percentage_selected": "(5.1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Expression analysis",
    "analytics": {
      "percent_correct": "88.6%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for references to cDNA. If we note that cDNA is mentioned in paragraphs 1, 3, 4, 5, and 7, we should then scan each of these sections of the text to determine which discusses the process of measuring gene expression via cDNA. Paragraph 3 touches upon this and reads: “The process of measuring gene expression via cDNA is called expression analysis or expression profiling.” This tells us that the process of measuring gene expression via cDNA is called expression analysis or expression profiling, but only expression analysis is listed in the answer choices. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Profiling analysis – is incorrect because paragraph 3 states that the process of measuring gene expression via cDNA is called expression analysis or expression profiling, not profiling analysis. Additionally, profiling analysis is not mentioned in the passage. Option B. Dynamic micro-mirroring – is incorrect because paragraph 3 states that the process of measuring gene expression via cDNA is called expression analysis or expression profiling, not dynamic micro-mirroring. Additionally, there is no such thing as dynamic micro-mirroring, only “dynamic micro-mirror devices,” as mentioned in paragraph 4. Option D. Photolithographic synthesis – is incorrect because paragraph 3 states that the process of measuring gene expression via cDNA is called expression analysis or expression profiling, not photolithographic synthesis. According to paragraph 6, photolithographic synthesis is a technique used to produce oligonucleotide arrays: “One technique used to produce oligonucleotide arrays includes photolithographic synthesis.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 28,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Which of the following are most often hybridized with two-channel microarrays?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "cDNA",
        "images": [],
        "percentage_selected": "(96.7%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "rDNA",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "mRNA",
        "images": [],
        "percentage_selected": "(0.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "cRNA",
        "images": [],
        "percentage_selected": "(2.2%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "tRNA",
        "images": [],
        "percentage_selected": "(0.1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "cDNA",
    "analytics": {
      "percent_correct": "96.7%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should first locate the paragraph or paragraphs discussing two-channel microarrays in the passage. This type of microarray is discussed in paragraph 7: “Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared…” This tells us that two-channel microarrays are typically hybridized with cDNA. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. rDNA – is incorrect because, in paragraph 7, the author says that two-channel or two-color microarrays are typically hybridized with cDNA, not rDNA. Option C. mRNA – is incorrect because, in paragraph 7, the author says that two-channel or two-color microarrays are typically hybridized with cDNA, not mRNA. Option D. cRNA – is incorrect because, in paragraph 7, the author says that two-channel or two-color microarrays are typically hybridized with cDNA, not cRNA. Option E. tRNA – is incorrect because, in paragraph 7, the author says that two-channel or two-color microarrays are typically hybridized with cDNA, not tRNA.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 29,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on certain hybridization conditions. Which of the following constitutes one such hybridization condition?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Salt concentration",
        "images": [],
        "percentage_selected": "(1.4%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Temperature",
        "images": [],
        "percentage_selected": "(85.4%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "pH levels",
        "images": [],
        "percentage_selected": "(3.7%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Guanine to cytosine ratio",
        "images": [],
        "percentage_selected": "(9.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Temperature",
    "analytics": {
      "percent_correct": "85.4%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the key phrase “hybridization conditions.” This phrase is mentioned only in paragraph 2: “Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature)…” This tells us that fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions, one example of which is temperature . Therefore, Option B is the correct answer.",
      "poe_text": "Option A. Salt concentration – is incorrect because, in paragraph 2, the author states that one possible hybridization condition is temperature, not salt concentration. Option C. pH levels – is incorrect because, in paragraph 2, the author states that one possible hybridization condition is temperature, not pH levels. Option D. Guanine to cytosine ratio – is incorrect because, in paragraph 2, the author states that one possible hybridization condition is temperature, not guanine to cytosine ratio.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 30,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "From which of the following sample pairs could two-color microarrays hybridized with cDNA be prepared?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "One sample each of diseased and healthy tissue",
        "images": [],
        "percentage_selected": "(95.8%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Two samples of diseased tissue",
        "images": [],
        "percentage_selected": "(2%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Two samples of healthy tissue",
        "images": [],
        "percentage_selected": "(1.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "One sample each of fresh and frozen tissue",
        "images": [],
        "percentage_selected": "(0.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "One sample each of diseased and healthy tissue",
    "analytics": {
      "percent_correct": "95.8%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph or paragraphs discussing two-channel microarrays. This type of microarray is discussed in paragraph 7. Regarding microarrays hybridized with cDNA, it reads: “Two-colour microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue)…” This tells us that the two possible sample pairs are diseased and healthy tissue. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Two samples of diseased tissue – is incorrect because, in paragraph 7, the author states that two-colour microarrays hybridized with cDNA could be prepared from samples of diseased AND healthy tissue, not two samples of diseased tissue: “Two-colour microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue)…” Option C. Two samples of healthy tissue – is incorrect because, in paragraph 7 the author states that two-colour microarrays hybridized with cDNA could be prepared from samples of diseased AND healthy tissue, not two samples of healthy tissue: “Two-colour microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue)…” Option D. One sample each of fresh and frozen tissue – is incorrect because, in paragraph 7, the author states that two-colour microarrays hybridized with cDNA could be prepared from samples of diseased and healthy tissue, not fresh and frozen tissue: “Two-colour microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue)…”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 31,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Which of the following fluorescent dyes is commonly used in two-channel microarrays?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Cy4",
        "images": [],
        "percentage_selected": "(0.5%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Cy5",
        "images": [],
        "percentage_selected": "(98.8%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "Cy6",
        "images": [],
        "percentage_selected": "(0.4%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Cy7",
        "images": [],
        "percentage_selected": "(0.1%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Cy8",
        "images": [],
        "percentage_selected": "(0.2%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Cy5",
    "analytics": {
      "percent_correct": "98.8%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph or paragraphs discussing two-channel microarrays. This type of microarray is discussed in-depth in Paragraph 7. Regarding fluorescent dyes, it reads: “Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm.” The only answer choice listed in the above paragraph is Cy5 red. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. Cy4 – is incorrect because this dye is not mentioned in the passage. Option C. Cy6 – is incorrect because this dye is not mentioned in the passage. Option D. Cy7 – is incorrect because this dye is not mentioned in the passage. Option E. Cy8 – is incorrect because this dye is not mentioned in the passage.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 32,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Which of the following microarray fabrication technologies is reliant on pre-made masks?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Ink-jet printing",
        "images": [],
        "percentage_selected": "(3.6%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Electrochemistry",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Photolithography",
        "images": [],
        "percentage_selected": "(89.4%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Printing with pins",
        "images": [],
        "percentage_selected": "(5.7%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Photolithography",
    "analytics": {
      "percent_correct": "89.4%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should locate the paragraph or paragraphs in the passage that discuss the fabrication of microarrays. If we note that this topic is covered in paragraphs 4 and 5, we should scan each of these sections to determine which mentions “pre-made masks.” These are referenced in paragraph 4: “Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks , photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays.” This tells us that photolithography is the type of technology that uses pre-made masks. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Ink-jet printing – is incorrect because paragraph 4 states that photolithography is the technology that uses pre-made masks, not ink-jet printing: “Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays.” Option B. Electrochemistry – is incorrect because paragraph 4 states that photolithography is the technology that uses pre-made masks, not electrochemistry: “Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays.” Option D. Printing with pins – is incorrect because paragraph 4 states that photolithography is the technology that uses pre-made masks, not printing with pins: “Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays.”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 33,
    "passage": {
      "title": "Passage 2",
      "text": "(1). A DNA microarray, also known as a DNA chip or biochip, is a collection of microscopic DNA spots attached to a solid surface. Scientists use DNA microarrays to measure the expression levels of large numbers of genes simultaneously and to genotype multiple regions of a genome. Each DNA spot in a DNA microarray contains picomoles of a specific DNA sequence, known as probes; these can be a short section of a gene or other DNA element used to hybridize a cDNA or cRNA sample under high-stringency conditions. Probe-target hybridization is usually detected and quantified by the detection of fluorophore-, silver-, or chemiluminescence-labeled targets to determine the relative abundance of nucleic acid sequences in the target. The original nucleic acid arrays were macro arrays approximately 9 cm × 12 cm, while the first computerized image-based analysis was published in 1981.\n\n(2). The core principle behind microarrays is hybridization between two DNA strands, with the property of complementary nucleic acid sequences to specifically pair with each other by forming hydrogen bonds amongst complementary nucleotide base pairs. A high number of complementary base pairs in a nucleotide sequence means tighter non-covalent bonding between the two strands. After washing off non-specific bonding sequences, only strongly paired strands will remain hybridized. Fluorescently labeled target sequences that bind to a probe sequence generate a signal dependent on hybridization conditions (such as temperature) and washing after hybridization; the total strength of the signal from a spot (feature) depends upon the amount of target sample binding to the probes present on that spot, while microarrays use relative quantitation in which the intensity of a feature is compared to the intensity of the same feature under a different condition, and the identity of the feature is known by its position.\n\n(3). The traditional solid-phase array is a collection of orderly microscopic “spots,” also known as “features,” each with thousands of identical and specific probes attached to a solid surface made of glass, plastic, or silicon biochip; thousands of these features can be placed in known locations on a single DNA microarray. The alternative bead array is a collection of microscopic polystyrene beads, each with a specific probe and a ratio of two or more dyes, which do not interfere with the fluorescent dyes used on the target sequence. DNA microarrays can be used to detect DNA or RNA that may or may not be translated into protein. The process of measuring gene expression via cDNA is called expression analysis or expression profiling.\n\n(4). Microarrays can be fabricated using a variety of technologies, such as printing with fine-pointed pins onto glass slides, photolithography using pre-made masks, photolithography using dynamic micro-mirror devices, ink-jet printing, or electrochemistry on micro-electrode arrays. In spotted microarrays, the probes are oligonucleotides, cDNA, or small fragments of PCR products that correspond to mRNAs; the probes are synthesized prior to deposition on the array surface and are then “spotted” onto the glass. A common approach to fabricating microarrays utilizes an array of fine pins or needles controlled by a robotic arm, which is dipped into wells containing DNA probes before depositing each probe at designated locations on the array surface.\n\n(5). The resulting “grid” of probes represents the nucleic acid profiles of the prepared probes and is ready to receive complementary cDNA or cRNA “targets” derived from experimental or clinical samples. This technique is used by research scientists around the world to produce “in-house” printed microarrays from their own labs; these arrays can be easily customized for individual experiments because researchers can choose the probes and printing locations on the arrays, synthesize the probes in their own lab (or in a collaborating facility) and spot the arrays. Researchers can then generate their own-labeled samples for hybridization, and hybridize the samples to the array before scanning the arrays with their own equipment. This results in a relatively low-cost microarray that is able to be customized for each individual study and avoids the need to purchase commercial arrays that are often both expensive and may represent vast numbers of genes that are not of interest to the researcher.\n\n(6). In oligonucleotide microarrays, the probes are short sequences designed to match parts of the sequence of known or predicted open reading frames. Oligonucleotide arrays are produced by printing short oligonucleotide sequences designed to represent a single gene or family of gene splice-variants by synthesizing this sequence directly onto the array surface instead of depositing intact sequences. Sequences may be longer (60-mer probes such as the Agilent design) or shorter (25-mer probes produced by Affymetrix) depending on the desired purpose; longer probes are more specific to individual target genes, while shorter probes may be spotted in higher density across the array and are also cheaper to manufacture. One technique used to produce oligonucleotide arrays includes photolithographic synthesis (Affymetrix) on a silica substrate where light and light-sensitive masking agents are used to “build” a sequence one nucleotide at a time across the entire array; each applicable probe is selectively “unmasked” prior to bathing the array in a solution of a single nucleotide before a masking reaction takes place, and the next set of probes are unmasked in preparation for a different nucleotide exposure.\n\n(7). Two-color microarrays, also known as two-channel microarrays, are typically hybridized with cDNA prepared from two samples to be compared (for instance, diseased tissue versus healthy tissue) and labeled with two different fluorophores. Fluorescent dyes that are commonly used for cDNA labeling include Cy3 green, which has a fluorescence emission wavelength of 570 nm, and Cy5 red, which has a fluorescence emission wavelength of 670 nm. The two Cy-labeled cDNA samples are mixed and hybridized into a single microarray that is then scanned in a microarray scanner to visualize the fluorescence of the two fluorophores after excitation with a laser beam of a defined wavelength. Relative intensities of each fluorophore may then be used in ratio-based analysis to identify up-regulated and down-regulated genes.\n\n(8). In single-channel microarrays or one-color microarrays, the arrays provide intensity data for each probe or probe set, indicating a relative level of hybridization within the labeled target. However, they do not truly indicate the abundance levels of a gene but rather its relative abundance when compared to other samples or conditions processed in the same experiment. Each RNA molecule encounters protocol- and batch-specific bias during the amplification, labeling, and hybridization phases of the experiment, making comparisons between genes for the same microarray uninformative. Additionally, the comparison of two conditions for the same gene requires two separate single-dye hybridizations.\n\n(9). Some popular single-channel systems are called the Affymetrix “Gene Chip”, Illumina “Bead Chip”, Agilent single-channel arrays, the Applied Microarrays “CodeLink” arrays, and the Eppendorf “DualChip & Silverquant.” A strength of the single-dye system lies in the fact that an aberrant sample cannot affect the raw data derived from other samples because each array chip is exposed to only one sample (as opposed to a two-color system in which a single low-quality sample may drastically impinge on overall data precision, even if the other sample was of high quality). Another benefit is that data are more easily compared to arrays from different experiments if batch effects have been accounted for.\n\n(10). Microarray data was found to be more useful when compared to other similar datasets. The sheer volume of data, specialized formats (such as MIAME), and curation efforts associated with the datasets require specialized databases to store the data. Thus, several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets and support analysis."
    },
    "question": {
      "text": "Which of the following is a warehouse solution created to integrate diverse biological datasets?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "InterMine",
        "images": [],
        "percentage_selected": "(78.4%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "MIAME",
        "images": [],
        "percentage_selected": "(15.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "BioMark",
        "images": [],
        "percentage_selected": "(4.2%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Silverquant",
        "images": [],
        "percentage_selected": "(1.8%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Topamax",
        "images": [],
        "percentage_selected": "(0.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "InterMine",
    "analytics": {
      "percent_correct": "78.4%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #2"
    },
    "category": "Passage #2",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph or paragraphs discussing storage solutions for microarray data. These solutions are discussed in paragraphs 9 and 10, with paragraph 10 discussing the integration of diverse biological datasets: “…several open-source data warehousing solutions, including InterMine and BioMart, have been created for the specific purpose of integrating diverse biological datasets…” This tells us that InterMine is one data warehousing solution used to integrate diverse biological datasets. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. MIAME – is incorrect because, in paragraph 10, the author states that: “The sheer volume of data, specialized formats (such as MIAME)…” This implies that MIAME is a format of data, not an open-source warehouse solution used to integrate diverse biological datasets. Option C. BioMark – is incorrect because BioMart is an open-source warehouse solution, not BioMark. Option D. Silverquant – is incorrect because this is a popular single-channel system, not an open-source warehouse solution used to integrate diverse biological datasets. Option E. Topamax – is incorrect because this is not mentioned in the passage.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 34,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Based on the passage, to what would the author agree that modern microscope design is attributed?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "The invention of the phase-contrast microscopy",
        "images": [],
        "percentage_selected": "(5.5%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Advancement in CCD technology",
        "images": [],
        "percentage_selected": "(6.4%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "The discovery that DAPI can be used to label",
        "images": [],
        "percentage_selected": "(4.1%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "The rise of fluorescence microscopy",
        "images": [],
        "percentage_selected": "(84%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "The rise of fluorescence microscopy",
    "analytics": {
      "percent_correct": "84%",
      "time_spent": "0 min, 6 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph or paragraphs discussing modern microscope design. Modern microscope design is mentioned only in paragraph 5: “The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope.” This tells us that the author believes modern microscope design is based on the rise of fluorescence microscopy. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. The invention of the phase-contrast microscopy – is incorrect because, in paragraph 6, the author states: “This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope.” This is not the same as saying that the modern microscope design is due to the invention of phase-contrast microscopy. Option B. Advancement in CCD technology – is incorrect because, in paragraph 6, the author states: …the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application.” This implies that CCD is an additional technology and is not necessary to digital microscopes. Additionally, this doesn’t mention anything about the modern microscope design; thus, it is incorrect. Option C. The discovery that DAPI can be used to label DNA – is incorrect because this is mentioned in paragraph 4: “The main groups of techniques involve targeted chemical staining of cell structures; for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein. These techniques use these different fluorophores for the analysis of cell structure at a molecular level in both live and fixed samples.” This method of labeling does not mention anything about the modern microscope design; thus, this is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 35,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "What factor enabled the practical application of fluorescence microscopy, and how long did it take?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Refurbished principles, 20 years",
        "images": [],
        "percentage_selected": "(1.5%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Laser technology, 21 years",
        "images": [],
        "percentage_selected": "(81.9%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "Laser technology, 23 years",
        "images": [],
        "percentage_selected": "(10.9%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Renewed insight, 20 years",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Supplementary research, 21 years",
        "images": [],
        "percentage_selected": "(4.5%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Laser technology, 21 years",
    "analytics": {
      "percent_correct": "81.9%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, first, we need to determine where in the passage the author discusses fluorescence microscopy development. The author discusses this topic in paragraph five: “The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time restricted the practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s.” This tells us that laser technology allowed the practical implementation of fluorescence microscopy. Since the confocal microscope was developed in 1957, but the first confocal laser scanning microscope wasn’t developed until 1978, the execution took 21 years . Therefore, Option B is the correct answer.",
      "poe_text": "Option A. Refurbished principles, 20 years – is incorrect because, in paragraph 5, the author says that laser technology’s patent, followed by its implementation 21 years later (1978-1951), allowed the practical application of fluorescence microscopy, not refurbished principles 20 years later. Option C. Laser technology, 23 years – is incorrect because, in paragraph 5, the author says that laser technology’s patent, followed by its implementation 21 years later (1978-1951), allowed the practical application of fluorescence microscopy, not 23 years later. Option D. Renewed insight, 20 years – is incorrect because, in paragraph 5, the author says that laser technology’s patent, followed by its implementation 21 years later (1978-1951), allowed the practical application of fluorescence microscopy, not renewed insight 20 years later. Option E. Supplementary research, 21 years – is incorrect because, in paragraph 5, the author says that laser technology’s patent, followed by its implementation 21 years later (1978-1951), allowed the practical application of fluorescence microscopy, not supplementary research 21 years later.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 36,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Which type of microscope operates in a similar manner to an optical microscope?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "The transmission electron microscope",
        "images": [],
        "percentage_selected": "(80.2%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "The confocal microscope",
        "images": [],
        "percentage_selected": "(9.8%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "A scanning probe microscope",
        "images": [],
        "percentage_selected": "(8.5%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "A scanning acoustic microscope",
        "images": [],
        "percentage_selected": "(1.5%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "The transmission electron microscope",
    "analytics": {
      "percent_correct": "80.2%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should scan the passage to determine which type of microscopes are compared to the optic microscope in the text. Only the electron microscope is compared to the optic microscope, as referenced in paragraph 3: “Working with electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope…” This tells us that the transmission electron microscope works in a similar manner to the optical microscope. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. The confocal microscope – is incorrect because paragraph 3 states that the transmission electron microscope works like the optic microscope, not the confocal microscope. Option C. A scanning probe microscope – is incorrect because paragraph 3 states that the transmission electron microscope works like the optic microscope, not the scanning probe microscope. Option D. A scanning acoustic microscope – is incorrect because paragraph 3 states that the transmission electron microscope works like the optic microscope, not the scanning probe microscope.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 37,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Which of the following materials is utilized in optical microscopes to focus light into the eye?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Quartz",
        "images": [],
        "percentage_selected": "(84.3%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Water",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Reflective glass",
        "images": [],
        "percentage_selected": "(13.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Laser beam",
        "images": [],
        "percentage_selected": "(0.9%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Electron detector",
        "images": [],
        "percentage_selected": "(0.7%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Quartz",
    "analytics": {
      "percent_correct": "84.3%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should determine wherein the passage optical microscopes are discussed most in-depth. It can be presumed that a description of their materials and the use of these materials will be included in such a discussion. Paragraph 2 discusses optical microscopes. Regarding the materials used in this type of device, it reads: “Optical microscopes have refractive glass, occasionally made of plastic or quartz , that focuses light into the user’s eye or into an alternate light detector.” This tells us that plastic or quartz is used to focus light into a user’s eye. However, only quartz is listed in the answer choices. Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Water – is incorrect because, in paragraph 2, the author says that optical microscopes use refractive glass made of plastic or quartz, not water, to focus light. Option C. Reflective glass – is incorrect because, in paragraph 2, the author says that optical microscopes use refractive glass made of plastic or quartz, not reflective glass, to focus light. Option D. Laser beam – is incorrect because, in paragraph 2, the author says that optical microscopes use refractive glass made of plastic or quartz, not a laser beam, to focus light. Option E. Electron detector – is incorrect because, in paragraph 2, the author says that optical microscopes use refractive glass made of plastic or quartz, or a light detector, not electron detectors to focus light.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 38,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "What is the ideal spectrum of light to improve the spatial resolution of an optical microscope?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Infrared light",
        "images": [],
        "percentage_selected": "(1.6%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Visible light",
        "images": [],
        "percentage_selected": "(4.8%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Ultraviolet light",
        "images": [],
        "percentage_selected": "(92.1%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "X-rays",
        "images": [],
        "percentage_selected": "(1.2%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Gamma rays",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Ultraviolet light",
    "analytics": {
      "percent_correct": "92.1%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should determine wherein the passage optical microscopes are discussed most in-depth; paragraph 2 thoroughly discusses optical microscopes. Regarding the improvement of their spatial resolution, it reads: “The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.” This tells us that ultraviolet light is the ideal spectrum of light to improve the spatial resolution of an optical microscope. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Infrared light – is incorrect because, in paragraph 2, the author says that the use of shorter wavelengths of light, such as ultraviolet, can improve spatial resolution of an optical microscope, not infrared light. This light is mentioned in paragraph 5: “Near infrared light can be used to visualize circuitry embedded in bonded silicon devices, since silicon is transparent in this region of wavelengths.” Option B. Visible light – is incorrect because, in paragraph 2, the author says that the use of shorter wavelengths of light, such as ultraviolet, can improve spatial resolution of an optical microscope, not visible light. Option D. X-rays – is incorrect because, in paragraph 2, the author says that the use of shorter wavelengths of light, such as ultraviolet, can improve spatial resolution of an optical microscope, not X-rays. This light is mentioned in paragraph 10: “This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects.” Option E. Gamma rays – is incorrect because, in paragraph 2, the author says that the use of shorter wavelengths of light, such as ultraviolet, can improve spatial resolution of an optical microscope, not gamma rays. Also, gamma rays are not mentioned in the passage.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 39,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Which word best defines “aperture” as used in paragraph 8?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Intersection",
        "images": [],
        "percentage_selected": "(0.9%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Apprehensive",
        "images": [],
        "percentage_selected": "(0.7%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Control gauge",
        "images": [],
        "percentage_selected": "(3.2%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Opening",
        "images": [],
        "percentage_selected": "(92.8%)",
        "is_correct": true
      },
      {
        "label": "E.",
        "text": "Shutter",
        "images": [],
        "percentage_selected": "(2.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Opening",
    "analytics": {
      "percent_correct": "92.8%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should look at the context in which the word “aperture” is used. Paragraph 8 reads: “A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through.” This tells us that an aperture is something that allows light to pass through. Thus, we can logically conclude that an aperture is an opening. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. Intersection – is incorrect because, according to paragraph 8, an aperture is something that should allow light to pass through, and light cannot pass through an intersection. Option B. Apprehensive – is incorrect because it is an adjective, while aperture is a noun. According to paragraph 8, an aperture is something that should allow light to pass through. Option C. Control gauge – is incorrect because light cannot pass through a control gauge. According to paragraph 8, an aperture is something that should allow light to pass through. Option E. Shutter – is incorrect because this word is used to describe something that lets in or blocks light. According to paragraph 8, an aperture is something that should allow light to pass through and would therefore not be closed like a shutter; thus, this is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 40,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "What is used to measure variations in acoustic impedance?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "X-rays",
        "images": [],
        "percentage_selected": "(3.9%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Sound waves",
        "images": [],
        "percentage_selected": "(93.2%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "Quartz vibration",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Silicon Probes",
        "images": [],
        "percentage_selected": "(1.1%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Ultraviolet light",
        "images": [],
        "percentage_selected": "(0.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Sound waves",
    "analytics": {
      "percent_correct": "93.2%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the key phrase “acoustic impedance.” This phrase is only found in paragraph 10, which reads: “Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance…” This tells us that acoustic microscopes use sound waves to measure variations in acoustic impedance. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. X-rays – is incorrect because this is mentioned in paragraph 9: “This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects.” This doesn’t indicate anything about variations in acoustic impedance; thus, it is incorrect. Option C. Quartz vibration – is incorrect because this is mentioned in paragraph 2: “Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector.” This doesn’t indicate anything about variations in acoustic impedance; thus, it is incorrect. Option D. Silicon Probes – is incorrect because this is mentioned in paragraph 7: “An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.” This doesn’t indicate anything about variations in acoustic impedance; thus, it is incorrect. Option E. Ultraviolet light – is incorrect because this is mentioned in paragraph 5: “Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye.” This doesn’t indicate anything about variations in acoustic impedance; thus, it is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 41,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Transmission and scanning electron microscopes are alike because both contain a number of electromagnetic and electrostatic lenses which focus a high-energy beam of electrons on a sample. X-ray microscopes employ the sonar principle to create images of objects.",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Both statements are TRUE",
        "images": [],
        "percentage_selected": "(7.3%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Both statements are FALSE",
        "images": [],
        "percentage_selected": "(6.9%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "The first statement is TRUE, the second is FALSE",
        "images": [],
        "percentage_selected": "(83.8%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "The first statement is FALSE, the second is TRUE",
        "images": [],
        "percentage_selected": "(1.9%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "The first statement is TRUE, the second is FALSE",
    "analytics": {
      "percent_correct": "83.8%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should first attempt to ascertain the veracity of the initial statement in the stem. This can be accomplished by searching the passage for the section or sections that discuss transmission and scanning electron microscopes.  These microscopes are discussed in the 3 rd paragraph. In paragraph 3, the author mentions the statement below. This tells us that transmission and scanning electron microscopes ARE similar as both have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample. Thus, the first statement is true. “The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample…” To verify the truth of the second statement in the question stem, scan the passage for the paragraph or paragraphs discussing the sonar principles. This principle is mentioned only in paragraph 10. In paragraph 10, the author mentions the statement below. This tells us that acoustic microscopes use the sonar principle, NOT X-ray microscopes. “Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits.” This means that the first statement is TRUE, but the second is FALSE. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Both statements are TRUE – is incorrect because the second statement is false. According to paragraph 10, acoustic microscopes use the sonar principle, not X-ray microscopes. Option B. Both statements are FALSE – is incorrect because the first statement is true. According to paragraph 3, TEM and SEM are similar as they both use electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample. Option D. The first statement is FALSE, the second is TRUE – is incorrect because the first statement is true, the second is false. According to paragraph 3, TEM and SEM are similar as they both use electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample. According to paragraph 10, acoustic microscopes use the sonar principle, not X-ray microscopes.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 42,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "If a researcher intends to visualize mitosis, what microscopy technique would the author suggest?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "A phase-contrast microscope",
        "images": [],
        "percentage_selected": "(84.7%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "A digital microscope",
        "images": [],
        "percentage_selected": "(8.4%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "An X-ray microscope",
        "images": [],
        "percentage_selected": "(2.8%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "An acoustic microscope",
        "images": [],
        "percentage_selected": "(4.1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "A phase-contrast microscope",
    "analytics": {
      "percent_correct": "84.7%",
      "time_spent": "0 min, 2 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, it is first necessary to understand the meaning of mitosis - mitosis is a part of the cell cycle in living cells; having ascertained this, we can now search the passage for a description of a microscope that visualizes the cell cycle in live cells. Paragraph 6 describes a microscope that visualizes the cell cycle in living cells. This tells us that the best way to visualize live cells, or mitosis, is through a phase-contrast microscope. It reads: “In contrast, phase-contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells…” Therefore, Option A is the correct answer.",
      "poe_text": "Option B. A digital microscope – is incorrect because, according to paragraph 6, phase-contrast microscopes can be used to visualize the cell cycle. Mitosis is a part of the cell cycle in live cells; thus, a researcher would use phase-contrast microscopes, not digital. This is mentioned in paragraph 6: “In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor.” Option C. An X-ray microscope – is incorrect because this is mentioned in paragraph 9: “This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed.” This doesn’t say anything about observing the cell cycle; thus, it is incorrect. Option D. An acoustic microscope – is incorrect because this is mentioned in paragraph 10: “… as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.” This doesn’t say anything about observing the cell cycle; thus, it is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 43,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "From what year does the earliest known example of a compound microscope date?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "1500",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "1620",
        "images": [],
        "percentage_selected": "(98%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "1935",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "1957",
        "images": [],
        "percentage_selected": "(0.7%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "1620",
    "analytics": {
      "percent_correct": "98%",
      "time_spent": "0 min, 4 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, consider that it asks us for information pertaining to an early form of the compound microscope; therefore, it is logical to presume that this information will be found towards the beginning of the passage. Indeed, paragraph 1 reads: “The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620 .” This tells us that the earliest known sample of a compound microscope dates to 1620. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. 1500 – is incorrect because paragraph 1 tells us that the compound microscope dates to the year 1620, not 1500. Option C. 1935 – is incorrect because 1935 was the year Max Knoll developed the scanning electron microscope, not the earliest known date of a compound microscope: “The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll.” Option D. 1957 – is incorrect because, according to paragraph 5, this was the year that Marvin Minsky patented the principle for the confocal microscope, not the earliest known date of a compound microscope. “The principle for the confocal microscope was patented in 1957 by Marvin Minsky…”",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 44,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "What type of microscopes use raster coils to scan the surface of specimens?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Transmission electron microscopes",
        "images": [],
        "percentage_selected": "(2.5%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Scanning tunneling microscopes",
        "images": [],
        "percentage_selected": "(5.7%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Scanning electron microscopes",
        "images": [],
        "percentage_selected": "(85.6%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Atomic force microscopes",
        "images": [],
        "percentage_selected": "(3.3%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Near-field scanning optical microscope",
        "images": [],
        "percentage_selected": "(2.9%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Scanning electron microscopes",
    "analytics": {
      "percent_correct": "85.6%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the key phrase “raster coils.” Raster coils are mentioned only in paragraph 3: “In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.” This tells us that scanning electron microscopes have raster coils. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Transmission electron microscopes – is incorrect because, in paragraph 3, the author says: “The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution.” This doesn’t mention anything about raster coils and thus is incorrect. Option B. Scanning tunneling microscopes – is incorrect because, in paragraph 8, the author says: “Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube, through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.” This doesn’t mention anything about raster coils and thus is incorrect. Option D. Atomic force microscopes – is incorrect because, in paragraph 7, the author says: “An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.” This doesn’t mention anything about raster coils and thus is incorrect. Option E. Near-field scanning optical microscope – is incorrect because, in paragraph 8, the author says: “A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through.” This doesn’t mention anything about raster coils  and thus is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 45,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Each of the following are a type of scanning probe microscope EXCEPT one. Which one is the EXCEPTION?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Scanning electron microscope",
        "images": [],
        "percentage_selected": "(82.4%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Atomic force microscopes",
        "images": [],
        "percentage_selected": "(8.5%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Scanning tunneling microscopes",
        "images": [],
        "percentage_selected": "(2.3%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Near-field scanning optical microscopes",
        "images": [],
        "percentage_selected": "(2%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Scanning near-field optical microscopy",
        "images": [],
        "percentage_selected": "(4.9%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Scanning electron microscope",
    "analytics": {
      "percent_correct": "82.4%",
      "time_spent": "0 min, 5 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph describing the scanning probe microscope. It can be presumed that the various forms of this microscope will be discussed in such a paragraph. Paragraph 7 discusses scanning probe microscopes most in-depth and reads: “The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy ), and scanning tunneling microscopes (STM).” Through the process of elimination, it can be determined that the only option choice NOT listed in the above paragraph is a scanning electron microscope . Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Atomic force microscopes – is incorrect because, according to paragraph 7, a scanning electron microscope is a type of scanning probe microscope; since this is mentioned, this cannot be the answer. Option C. Scanning tunneling microscopes – is incorrect because, according to paragraph 7, an atomic force microscope is a type of scanning probe microscope; since this is mentioned, this cannot be the answer. Option D. Near-field scanning optical microscopes – is incorrect because, according to paragraph 7, a scanning tunneling microscope is a type of scanning probe microscope; since this is mentioned, this cannot be the answer. Option E. Scanning near-field optical microscopy – is incorrect because, according to paragraph 7, scanning near-field optical microscopy is a type of scanning probe microscope; since this is mentioned, this cannot be the answer.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 46,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "What substance is contained in the probe of a near-field scanning optical microscope?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Optical fiber",
        "images": [],
        "percentage_selected": "(79.6%)",
        "is_correct": true
      },
      {
        "label": "B.",
        "text": "Metal fiber",
        "images": [],
        "percentage_selected": "(3.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Silicon fiber",
        "images": [],
        "percentage_selected": "(15.2%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Glass fiber",
        "images": [],
        "percentage_selected": "(1.8%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Steel cords",
        "images": [],
        "percentage_selected": "(0.3%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Optical fiber",
    "analytics": {
      "percent_correct": "79.6%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph describing the near-field scanning optical microscope. It can be presumed that the materials used in this device will be contained within such a paragraph. Paragraph 8 discusses near-field scanning optical microscopes most in-depth and reads: “A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip…” This tells us that the probe of a near-field scanning optical microscope contains optical fiber . Therefore, Option A is the correct answer.",
      "poe_text": "Option B. Metal fiber – is incorrect because according to paragraph 8, a near-field scanning optical microscope contains optical fiber, not metal fiber. A scanning tunneling microscope has a metal tip. Option C. Silicon fiber – is incorrect because according to paragraph 8, a near-field scanning optical microscope contains optical fiber, not silicon fiber. An atomic force microscope has a silicon probe. Option D. Glass fiber – is incorrect because according to paragraph 8, a near-field scanning optical microscope contains optical fiber, not glass fiber. Glass probes are not mentioned in the passage. Option E. Steel cords – is incorrect because according to paragraph 8, a near-field scanning optical microscope contains optical fiber, not steel chords. Steel is not mentioned in the passage.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 47,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Which of the following microscopy techniques employs a tube to create a current flow and produce an image of an object?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Atomic force microscopes",
        "images": [],
        "percentage_selected": "(4.6%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Near-field scanning optical microscopes",
        "images": [],
        "percentage_selected": "(11.4%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Scanning near-field optical microscopy",
        "images": [],
        "percentage_selected": "(5.9%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Scanning tunneling microscopes",
        "images": [],
        "percentage_selected": "(78.1%)",
        "is_correct": true
      }
    ],
    "correct_answer_text": "Scanning tunneling microscopes",
    "analytics": {
      "percent_correct": "78.1%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should scan the descriptions of the various types of microscopes discussed in the passage to determine which uses a tube to generate a current flow and create an image of an object. “ Scanning tunneling microscopes have a metal tip with a single apical atom and the tip is attached to a tube, through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.” This tells us that scanning tunneling microscopes use a tube to generate a current flow and create an image of an object. Therefore, Option D is the correct answer.",
      "poe_text": "Option A. Atomic force microscopes – is incorrect because according to paragraph 8, the microscopy technique that uses a tube to generate a current flow and create an image is a scanning tunneling microscope, not an atomic force microscope. In paragraph 7, the author says: “An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.” Option B. Near-field scanning optical microscopes – is incorrect because in paragraph 8, the author says: “A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen.” This doesn’t mention a tube to generate a current flow and create an image, and thus is incorrect. Option C. Scanning near-field optical microscopy – is incorrect because this is mentioned in paragraph 7: “The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM).” This doesn’t mention a tube to generate a current flow and create an image, and thus is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 48,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Which of the following is the most structurally akin to the transmission electron microscope?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Near-field scanning optical microscopes",
        "images": [],
        "percentage_selected": "(1.9%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Optical microscopes",
        "images": [],
        "percentage_selected": "(45.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "Scanning electron microscopes",
        "images": [],
        "percentage_selected": "(51.6%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "Atomic force microscopes",
        "images": [],
        "percentage_selected": "(1.4%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Scanning electron microscopes",
    "analytics": {
      "percent_correct": "51.6%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph describing the transmission electron microscope. Paragraph 3 discusses this type of microscope and reads: “The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample...” This tells us that the transmission electron microscope is similar in nature to the scanning electron microscope. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. Near-field scanning optical microscopes – is incorrect because in paragraph 2, the author says, “The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.” This is all the author mentions about this device, and thus we cannot conclude that there are similarities between this and the transmission electron microscope. Option B. Optical microscopes – is incorrect because the only similarity between optical microscopes and transmission electron microscopes is that they work on similar principles according to the passage; therefore, this is not enough information to infer that there are any other similarities. Option D. Atomic force microscopes – is incorrect because in paragraph 7, the author says, “An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.” This microscope doesn’t have anything in common with how a transmission electron microscope functions, and thus, this is incorrect.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 49,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "What type of tip does the probe contain in a scanning tunneling microscope (STM)?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "Fiber",
        "images": [],
        "percentage_selected": "(2.1%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "Metal",
        "images": [],
        "percentage_selected": "(69.4%)",
        "is_correct": true
      },
      {
        "label": "C.",
        "text": "Silicon",
        "images": [],
        "percentage_selected": "(19.2%)",
        "is_correct": false
      },
      {
        "label": "D.",
        "text": "Glass",
        "images": [],
        "percentage_selected": "(1.3%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "Apical atom",
        "images": [],
        "percentage_selected": "(8.1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "Metal",
    "analytics": {
      "percent_correct": "69.4%",
      "time_spent": "0 min, 3 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should search the passage for the paragraph describing the scanning tunnelling microscope. It can be presumed that such a paragraph will include descriptions of the scanning tunnelling microscope’s components. Paragraph 8 discusses this type of microscope, as well as its parts, and reads: “Scanning tunneling microscopes have a metal tip with a single apical atom…” This tells us that the tip is metal. Therefore, Option B is the correct answer.",
      "poe_text": "Option A. Fiber – is incorrect because in paragraph 8, the author says that scanning tunneling microscopes have a metal tip, not a fiber tip. Paragraph 8 states: “A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through.” Option C. Silicon – is incorrect because in paragraph 8, the author says that scanning tunneling microscopes have a metal tip, not a silicon tip. Paragraph 7 states: “An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.” Option D. Glass – is incorrect because in paragraph 8, the author says that scanning tunneling microscopes have a metal tip, not a glass tip. Glass tips are not mentioned in the passage; however, glass is mentioned in paragraph 2: “Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector.” Option E. Apical atom – is incorrect because while a scanning tunneling microscope has a tip with a single apical atom, the tip itself is not composed of the same.",
      "images": []
    }
  },
  {
    "test_number": 5,
    "question_number": 50,
    "passage": {
      "title": "Passage 3",
      "text": "(1). A microscope (name derived from the Ancient Greek word “mikrós,” meaning “small” and “skopeîn,” meaning “to look” or “to see”) is an instrument used to view objects that are much too minute to be seen by the naked eye. There are many types of microscopes, and they may be grouped differently. One way to group microscopes is by describing the way in which the instrument interacts with a sample to create images (either by sending a beam of light or electrons to a sample in its optical path or by scanning across a short distance from the surface of a sample using a probe). Objects resembling lenses date back 4000 years - for instance, there are Greek accounts of the optical properties of water-filled spheres from the 5th century BC, followed by many centuries of writings on optics. The earliest known use of simple microscopes (magnifying glasses) dates to the widespread use of lenses in eyeglasses in the 13th century. The earliest known examples of compound microscopes, which combine an objective lens near a specimen with an eyepiece to view a real image, appeared in Europe around the year 1620.\n\n(2). The inaugural and most common type of microscope is the optical microscope, an optical instrument containing one or more lenses that produce an enlarged image of a sample placed in the microscope’s focal plane. Optical microscopes have refractive glass, occasionally made of plastic or quartz, that focuses light into the user’s eye or into an alternate light detector. A type of microscope that operates in the same manner as the optical microscope is the light microscope; typical magnification of a light microscope, assuming visible range light, is up to 1250x with a theoretical resolution limit of around 0.250 micrometers (this limits the practical magnification limit to ~1500x). The use of shorter wavelengths of light, such as ultraviolet light, is one way to improve the spatial resolution of the optical microscope, as are devices like the near field scanning optical microscope.\n\n(3). Working with the electrical engineer Max Knoll, German physicist Ernst Ruska developed the first prototype electron microscope in 1931, which was a transmission electron microscope (TEM). The transmission electron microscope works similarly to an optical microscope but uses electrons in the place of light and electromagnets in the place of glass lenses because using electrons instead of light allows for much higher resolution. The development of the transmission electron microscope was quickly followed in 1935 by the development of the scanning electron microscope (SEM) by Max Knoll. Both types of microscopes have a series of electromagnetic and electrostatic lenses to focus a high-energy beam of electrons on a sample, but in a transmission electron microscope, the electrons pass through the sample, analogous to basic optical microscopy; this requires careful preparation of samples, since electrons are scattered strongly by most materials. In contrast, scanning electron microscopes have raster coils to scan the surface of bulk objects with a fine electron beam.\n\n(4). The most recent advances in microscope development centre primarily on the rise of fluorescence microscopy in biology, the main groups of techniques involve targeted chemical staining of cell structures (for example, the chemical compound DAPI to label DNA, use of antibodies conjugated to fluorescent reporters, and immunofluorescence and fluorescent proteins, such as green fluorescent protein). Such techniques use the abovementioned varied fluorophores for analysis of cell structure at a molecular level in both live and fixed samples.\n\n(5). The rise of fluorescence microscopy drove the development of a major modern microscope design, this being the confocal microscope. The principle for the confocal microscope was patented in 1957 by Marvin Minsky, although the limitations of laser technology at the time-restricted practical application of Minsky’s technique. It was not until 1978, when Thomas and Christoph Cremer developed the first practical confocal laser scanning microscope, that the technique rapidly gained popularity, especially in the 1980s. Ultraviolet light enables the resolution of microscopic features, as well as image samples that are transparent to the eye. Near-infrared light can be used to visualize circuitry embedded in bonded silicon devices since silicon is transparent in this region of wavelengths. In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.\n\n(6). In contrast, phase contrast microscopy is an optical microscopy illumination technique in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells, and the traditional optical microscope has more recently evolved into the digital microscope. In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor; these sensors may use CMOS or charge-coupled device (CCD) technology, depending on the application. Digital microscopy with very low light levels (intended to avoid damage to vulnerable biological samples) is available using sensitive photon-counting digital cameras. It has been demonstrated that a light source providing pairs of entangled photons may minimize the risk of damage to the most light-sensitive samples. In this application of ghost imaging to photon-sparse microscopy, the sample is illuminated with infrared photons, each of which is spatially correlated with an entangled partner in the visible band, for efficient imaging by a photon-counting camera.\n\n(7). The various types of scanning probe microscopes arise from the many different types of interactions that occur when a small type of probe is scanned over and interacts with a specimen. The three most common types of scanning probe microscopes are atomic force microscopes (AFM), near-field scanning optical microscopes (NSOM or SNOM, scanning near-field optical microscopy), and scanning tunneling microscopes (STM). An atomic force microscope has a fine probe, usually made of silicon or silicon nitride, attached to a cantilever. The probe is scanned over the surface of the sample, and the forces that cause an interaction between the probe and the surface of the sample are then measured and mapped.\n\n(8). A near-field scanning optical microscope resembles an AFM, but its probe consists of a light source in an optical fiber covered with a tip that usually has an aperture that allows the light to pass through. The microscope can capture either transmitted or reflected light to measure very localized optical properties of a surface, commonly that of a biological specimen. Scanning tunneling microscopes have a metal tip with a single apical atom, and the tip is attached to a tube through which a current can pass. The tip of the microscope is scanned over the surface of a conductive sample until the abovementioned tunneling current flows; this current is kept constant by the computer-driven movement of the microscope’s tip, and an image is formed by the recorded movements of the tip.\n\n(9). Technological advances in x-ray lens optics in the early 1970s made the instrument a viable imaging choice. This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.\n\n(10). Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.\n\n(11): The electronics industry often uses scanning acoustic microscopes to locate flaws and defects within the internal components of technological devices. This is necessary because such defects may impact the optimal function of these machines, making them potentially unreliable. This type of quality control is especially pivotal in the automotive, construction, and aerospace industries, where dependability is paramount to the safety and well-being of countless individuals. In the construction industry, scanning acoustic microscopes can pinpoint cracks and deficits in composite materials, such as ceramics and glass, which may lead to structural weaknesses. The microscopes are also employed in the field of biomedical research, where they are used to examine cells, tissues, and bones in a way that does not cause undue damage to the samples. Biomedical researchers can examine these samples with scanning acoustic microscopes to study tissue alterations caused by disease and treatment of disease.\n\n(12). Microscopes have had an enormous influence on the development of modern medical, forensics, and environmental science. The invention of the microscope has revolutionized the science industry, as well as aided in other fields. With advancements in technology in the centuries to come, it is expected that many more microscopy techniques will be developed.\n\n(13.) Microscopes have shaped contemporary scientific practices in different ways; for instance, Dutch microbiologist Antonie van Leeuwenhoek’s 17th-century work with microscopes helped form our modern understanding of germ theory. Van Leeuwenhoek was the first to view microorganisms at a microscopic level, leading to the understanding that such organisms are the root cause of many common diseases. In turn, this discovery led up to the evolution of germ theory, which supplied the scientific basis for modern sanitation and infection control protocols, as well as the creation of antibiotics. Microscopes have shaped modern practices in the field of forensics because they allow scientists to better examine trace evidence such as hair and fibers, helping to link suspects to crimes using methods that would not be possible otherwise. Finally, microscopes have impacted environmental science because they allow researchers to more effectively study, for instance, particulate matter in the air, soil sediments, and microplastics."
    },
    "question": {
      "text": "Which microscope functions in the most similar manner to a camera?",
      "images": []
    },
    "options": [
      {
        "label": "A.",
        "text": "The fluorescence microscope",
        "images": [],
        "percentage_selected": "(5.1%)",
        "is_correct": false
      },
      {
        "label": "B.",
        "text": "The phase-contrast microscope",
        "images": [],
        "percentage_selected": "(25.1%)",
        "is_correct": false
      },
      {
        "label": "C.",
        "text": "The digital microscope",
        "images": [],
        "percentage_selected": "(63.7%)",
        "is_correct": true
      },
      {
        "label": "D.",
        "text": "The X-ray microscope",
        "images": [],
        "percentage_selected": "(5%)",
        "is_correct": false
      },
      {
        "label": "E.",
        "text": "The acoustic microscope",
        "images": [],
        "percentage_selected": "(1%)",
        "is_correct": false
      }
    ],
    "correct_answer_text": "The digital microscope",
    "analytics": {
      "percent_correct": "63.7%",
      "time_spent": "0 min, 6 secs",
      "category": "Passage #3"
    },
    "category": "Passage #3",
    "explanation": {
      "concept_text": "To answer this question, we should scan the descriptions of each microscope in the passage to determine which is like a camera - only the digital microscope, as mentioned in paragraph 6, is said to function like a camera: “…the traditional optical microscope has more recently evolved into the digital microscope . In addition to - or instead of - directly viewing the object through the eyepieces, a type of sensor, like those used in digital cameras, is used to obtain an image, which is then displayed on a computer monitor…” Thus, the digital microscope functions most like a camera. Therefore, Option C is the correct answer.",
      "poe_text": "Option A. The fluorescence microscope – is incorrect because, in paragraph 5, the author says: “In fluorescence microscopy, many wavelengths of light - ranging from the ultraviolet to the visible - can be used to cause samples to fluoresce and allow viewing by eye or with the use of specifically sensitive cameras.” This is not the same as saying that fluorescence microscopy functions like a camera. Option B. The phase-contrast microscope – is incorrect because, in paragraph 6, the author says: “In contrast, phase contrast microscopy is an optical microscopy illumination technique, in which small phase shifts in the light passing through a transparent specimen are converted into amplitude or contrast changes in the image - the use of phase contrast does not require staining to view the slide. This microscope technique made it possible to study the cell cycle in live cells …” This doesn’t mention any similarities to cameras, and thus, is incorrect. Option D. The X-ray microscope – is incorrect because, in paragraph 9, the author says: “This was made possible with X-ray microscopes, instruments that use electromagnetic radiation, most often in the soft X-ray band to image objects. They are also frequently used in tomography to produce three-dimensional images of objects, including biological materials that have not been chemically fixed. Currently, research is being done to improve optics for hard x-rays, which have a greater penetrating power.” This doesn’t mention any similarities to cameras and, thus, is incorrect. Option E. The acoustic microscope – is incorrect because, in paragraph 10, the author says: “Scanning acoustic microscopes were created soon after the aforementioned advances in x-ray lens optics. Scanning acoustic microscopes utilize sound waves to measure variations in acoustic impedance, and, as with the sonar principle, they are employed in tasks such as detecting defects in the subsurface of materials, including those found in integrated circuits. The key advantage of this type of microscope is that it implements non-invasive and non-destructive techniques that can be used to image the internal features of a specimen, notably its interfaces.” This doesn’t mention any similarities to cameras and, thus, is incorrect.",
      "images": []
    }
  }
]